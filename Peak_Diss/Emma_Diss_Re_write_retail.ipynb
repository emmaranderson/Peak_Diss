{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62iiPEpGdPsC",
    "outputId": "27b7c388-8438-4f73-99c5-d56e0e9a940c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from random import randint \n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, plot_confusion_matrix, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from multi_imbalance.resampling.mdo import MDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zB7KgSFTfciI"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = pd.read_csv('cust_summary_clustered.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstorder_grosssales</th>\n",
       "      <th>firstorder_units</th>\n",
       "      <th>class</th>\n",
       "      <th>loyaltyaccount_No</th>\n",
       "      <th>loyaltyaccount_Yes</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender_unknown</th>\n",
       "      <th>shipcountry_Albania</th>\n",
       "      <th>shipcountry_Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>category_Childrens</th>\n",
       "      <th>category_Infant</th>\n",
       "      <th>category_Junior</th>\n",
       "      <th>category_Mens</th>\n",
       "      <th>category_Miscellaneous</th>\n",
       "      <th>category_Nursery</th>\n",
       "      <th>category_Womens</th>\n",
       "      <th>divisioncode_ACCESSORY</th>\n",
       "      <th>divisioncode_APPAREL</th>\n",
       "      <th>divisioncode_FOOTWEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.82</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstorder_grosssales  firstorder_units  class  loyaltyaccount_No  \\\n",
       "0                  64.82                 2      0                  1   \n",
       "\n",
       "   loyaltyaccount_Yes  gender_female  gender_male  gender_unknown  \\\n",
       "0                   0              1            0               0   \n",
       "\n",
       "   shipcountry_Albania  shipcountry_Armenia  ...  category_Childrens  \\\n",
       "0                    0                    0  ...                   0   \n",
       "\n",
       "   category_Infant  category_Junior  category_Mens  category_Miscellaneous  \\\n",
       "0                0                0              0                       0   \n",
       "\n",
       "   category_Nursery  category_Womens  divisioncode_ACCESSORY  \\\n",
       "0                 0                1                       0   \n",
       "\n",
       "   divisioncode_APPAREL  divisioncode_FOOTWEAR  \n",
       "0                     0                      1  \n",
       "\n",
       "[1 rows x 86 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail = retail.rename(columns={'cluster':'class'})\n",
    "retail.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail['class'] = retail['class'].replace({2: 1, 1: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1932069\n",
      "1     249970\n",
      "2      22834\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(retail['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.876272\n",
       "1    0.113372\n",
       "2    0.010356\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class\n",
      "0  193206\n",
      "1   24997\n",
      "2    2283\n"
     ]
    }
   ],
   "source": [
    "print((retail['class'].value_counts()*0.10).astype('int64').to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_0 = retail[(retail['class'] == 0)] \n",
    "retail_0 = retail_0.sample(n= 193206)\n",
    "retail_1 = retail[(retail['class'] == 1)] \n",
    "retail_1 = retail_1.sample(n= 24997)\n",
    "retail_2 = retail[(retail['class'] == 2)] \n",
    "retail_2 = retail_2.sample(n= 2283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.876273\n",
       "1    0.113372\n",
       "2    0.010354\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_down = pd.concat([retail_0, retail_1, retail_2])\n",
    "retail_down = shuffle(retail_down)\n",
    "retail_down.name = 'Retail - sample'\n",
    "retail_down['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>firstorder_grosssales</th>\n",
       "      <th>firstorder_units</th>\n",
       "      <th>month_April</th>\n",
       "      <th>month_August</th>\n",
       "      <th>month_December</th>\n",
       "      <th>month_February</th>\n",
       "      <th>month_January</th>\n",
       "      <th>month_July</th>\n",
       "      <th>month_June</th>\n",
       "      <th>...</th>\n",
       "      <th>category_Nursery</th>\n",
       "      <th>category_Womens</th>\n",
       "      <th>divisioncode_ACCESSORY</th>\n",
       "      <th>divisioncode_APPAREL</th>\n",
       "      <th>divisioncode_FOOTWEAR</th>\n",
       "      <th>loyaltyaccount_No</th>\n",
       "      <th>loyaltyaccount_Yes</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>66.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17.45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>253.48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  firstorder_grosssales  firstorder_units  month_April  month_August  \\\n",
       "0      0                  66.10                 2            0             0   \n",
       "1      0                  66.10                 2            0             0   \n",
       "2      2                  17.45                 2            0             1   \n",
       "3      0                  36.14                 2            0             0   \n",
       "4      0                 253.48                 3            0             0   \n",
       "\n",
       "   month_December  month_February  month_January  month_July  month_June  ...  \\\n",
       "0               0               0              0           0           0  ...   \n",
       "1               0               0              0           0           0  ...   \n",
       "2               0               0              0           0           0  ...   \n",
       "3               0               0              0           1           0  ...   \n",
       "4               1               0              0           0           0  ...   \n",
       "\n",
       "   category_Nursery  category_Womens  divisioncode_ACCESSORY  \\\n",
       "0                 0                0                       0   \n",
       "1                 0                0                       0   \n",
       "2                 0                0                       0   \n",
       "3                 0                0                       0   \n",
       "4                 0                1                       0   \n",
       "\n",
       "   divisioncode_APPAREL  divisioncode_FOOTWEAR  loyaltyaccount_No  \\\n",
       "0                     0                      1                  1   \n",
       "1                     0                      1                  1   \n",
       "2                     1                      0                  1   \n",
       "3                     1                      0                  0   \n",
       "4                     0                      1                  1   \n",
       "\n",
       "   loyaltyaccount_Yes  gender_female  gender_male  gender_unknown  \n",
       "0                   0              1            0               0  \n",
       "1                   0              1            0               0  \n",
       "2                   0              1            0               0  \n",
       "3                   1              1            0               0  \n",
       "4                   0              1            0               0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_new = pd.read_csv('clusters_new.csv', index_col=0)\n",
    "retail_new = retail_new.rename(columns={'cluster':'class'})\n",
    "retail_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1333494\n",
      "2     749227\n",
      "1     122134\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(retail_new['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.604799\n",
       "2    0.339808\n",
       "1    0.055393\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_new['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= retail_new.drop('class',axis=1).copy()\n",
    "y = retail_new['class'].copy()\n",
    "y = y.astype('category')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2, shuffle=y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_new = pd.DataFrame(X_test, columns = X.columns)\n",
    "retail_new['class'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    133350\n",
      "2     74923\n",
      "1     12213\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(retail_new['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_new.name = 'Retail - new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstorder_grosssales</th>\n",
       "      <th>firstorder_units</th>\n",
       "      <th>month_April</th>\n",
       "      <th>month_August</th>\n",
       "      <th>month_December</th>\n",
       "      <th>month_February</th>\n",
       "      <th>month_January</th>\n",
       "      <th>month_July</th>\n",
       "      <th>month_June</th>\n",
       "      <th>month_March</th>\n",
       "      <th>...</th>\n",
       "      <th>category_Womens</th>\n",
       "      <th>divisioncode_ACCESSORY</th>\n",
       "      <th>divisioncode_APPAREL</th>\n",
       "      <th>divisioncode_FOOTWEAR</th>\n",
       "      <th>loyaltyaccount_No</th>\n",
       "      <th>loyaltyaccount_Yes</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender_unknown</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654230</th>\n",
       "      <td>77.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418204</th>\n",
       "      <td>26.21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940088</th>\n",
       "      <td>71.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765465</th>\n",
       "      <td>26.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650403</th>\n",
       "      <td>99.68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         firstorder_grosssales  firstorder_units  month_April  month_August  \\\n",
       "654230                   77.92                 1            1             0   \n",
       "1418204                  26.21                 2            0             0   \n",
       "1940088                  71.10                 1            0             0   \n",
       "1765465                  26.98                 2            0             0   \n",
       "650403                   99.68                 2            0             0   \n",
       "\n",
       "         month_December  month_February  month_January  month_July  \\\n",
       "654230                0               0              0           0   \n",
       "1418204               0               0              0           0   \n",
       "1940088               0               0              0           0   \n",
       "1765465               0               0              0           0   \n",
       "650403                0               0              0           0   \n",
       "\n",
       "         month_June  month_March  ...  category_Womens  \\\n",
       "654230            0            0  ...                1   \n",
       "1418204           1            0  ...                0   \n",
       "1940088           1            0  ...                0   \n",
       "1765465           1            0  ...                0   \n",
       "650403            0            1  ...                0   \n",
       "\n",
       "         divisioncode_ACCESSORY  divisioncode_APPAREL  divisioncode_FOOTWEAR  \\\n",
       "654230                        0                     0                      1   \n",
       "1418204                       0                     1                      0   \n",
       "1940088                       0                     0                      1   \n",
       "1765465                       1                     0                      0   \n",
       "650403                        0                     0                      1   \n",
       "\n",
       "         loyaltyaccount_No  loyaltyaccount_Yes  gender_female  gender_male  \\\n",
       "654230                   1                   0              0            1   \n",
       "1418204                  1                   0              1            0   \n",
       "1940088                  1                   0              0            1   \n",
       "1765465                  1                   0              1            0   \n",
       "650403                   0                   1              0            1   \n",
       "\n",
       "         gender_unknown  class  \n",
       "654230                0      2  \n",
       "1418204               0      0  \n",
       "1940088               0      0  \n",
       "1765465               0      0  \n",
       "650403                0      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OsUspqauau3P"
   },
   "outputs": [],
   "source": [
    "# train test/ scaling\n",
    "def data_prep (data, seed):\n",
    "  X= data.drop('class',axis=1).copy()\n",
    "  y = data['class'].copy()\n",
    "  y = y.astype('category')\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed, shuffle=y, stratify=y) # add ssed\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train_scaled = scaler.transform(X_train)\n",
    "  X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "  X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n",
    "  X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SNuXHNsxyhaB"
   },
   "outputs": [],
   "source": [
    "def random_under_minority (data, imbalance_level, seed):\n",
    "  if imbalance_level == 'none':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data_prep(data, 1)\n",
    "    X_train_scaled = X_train_scaled.reset_index(drop=True).values\n",
    "    X_test_scaled = X_test_scaled.reset_index(drop=True).values\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "  \n",
    "  else:\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data_prep(data, 1)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    X_train_scaled['class'] = y_train\n",
    "\n",
    "    class_counts = X_train_scaled['class'].value_counts().to_frame()\n",
    "\n",
    "    minority_full = pd.DataFrame()\n",
    "    for c in range(1,len(class_counts)):\n",
    "      maj_count = class_counts.iloc[0,0]\n",
    "      min_count = class_counts.iloc[c,0]\n",
    "\n",
    "      majority = X_train_scaled[(X_train_scaled['class'] == 0)]\n",
    "      minority = X_train_scaled[(X_train_scaled['class']== c)]\n",
    "\n",
    "      if imbalance_level == 'absolute':\n",
    "          downsample = 6\n",
    "  \n",
    "      else:\n",
    "        if imbalance_level == 'high':\n",
    "          imbalance = 0.05\n",
    "      \n",
    "        elif imbalance_level == 'extreme':\n",
    "          imbalance = 0.01\n",
    "\n",
    "        downsample = (maj_count * imbalance).round().astype('int')\n",
    "    \n",
    "      if imbalance_level == 'extreme' and downsample < 8:\n",
    "        downsample = 8\n",
    "\n",
    "      if downsample < 6:\n",
    "        downsample = 6 \n",
    " \n",
    "      if downsample >= min_count:\n",
    "        minority_sample = minority\n",
    "      \n",
    "      \n",
    "      else:\n",
    "        minority_sample = minority.sample(n= downsample)\n",
    "\n",
    "      minority_full = pd.concat([minority_full, minority_sample])\n",
    "    final = pd.concat([majority, minority_full])\n",
    "    final = shuffle(final)\n",
    "\n",
    "    X_train_scaled = final.drop('class',axis=1).copy()\n",
    "    y_train = final['class'].copy()\n",
    "    y_train = y_train.astype('category')\n",
    "\n",
    "    X_train_scaled = X_train_scaled.reset_index(drop=True).values\n",
    "    X_test_scaled = X_test_scaled.reset_index(drop=True).values\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "z8NQNtO3a1dX"
   },
   "outputs": [],
   "source": [
    "def SMOTE_sampling (data, imbalance, seed):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  SMOTE_sample = SMOTE()\n",
    "  X_train_scaled, y_train = SMOTE_sample.fit_resample(X_train_scaled, y_train)\n",
    "  \n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nu5ULZ_KMl0B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "class SingularMatrixException(Exception):\n",
    "    def __init__(self):\n",
    "        Exception.__init__(self,\"Singular data matrix... use subspace\") \n",
    "\n",
    "def _msqrt(X):\n",
    "    '''Computes the square root matrix of symmetric square matrix X.'''\n",
    "    (L, V) = np.linalg.eig(X)\n",
    "    return V.dot(np.diag(np.sqrt(L))).dot(V.T) \n",
    "\n",
    "\n",
    "class SwimMaha:\n",
    "\n",
    "    def __init__(self, sd=0.25, minClass=None, subSpaceSampling=False):\n",
    "        self.sd = sd\n",
    "        self.minClass = minClass\n",
    "        self.subSpaceSampling = subSpaceSampling\n",
    "\n",
    "    # the data passed is transposed, so the rows are the features, and the columns are the instances\n",
    "    def mahaSampling(self, data, labels, numSamples):\n",
    "\n",
    "        if self.minClass == None:\n",
    "            self.minClass     = np.argmin(np.bincount(labels.astype(int)))\n",
    "\n",
    "        syntheticInstances  = []\n",
    "        data_maj_orig       = data[np.where(labels!=self.minClass)[0], :]\n",
    "        data_min_orig       = data[np.where(labels==self.minClass)[0], :]\n",
    "        data_min_orig = data_min_orig+0.0001*np.random.rand((data_min_orig.shape)[0],(data_min_orig.shape)[1])\n",
    "\n",
    "        if(np.sum(labels==self.minClass)==1):\n",
    "            data_min_orig = data_min_orig.reshape(1,len(data_min_orig))\n",
    "            # trnMinData    = trnMinData.reshape(1,len(trnMinData))\n",
    "\n",
    "        ## STEP 1: CENTRE\n",
    "        ## CENTRE THE MAJORITY CLASS AND CENTRE THE MINORITY CLASS WITH RESPECT TO THE MAJORITY CLASS\n",
    "        scaler = StandardScaler(with_std=False)\n",
    "        T_maj  = np.transpose(scaler.fit_transform(data_maj_orig))\n",
    "        T_min  = np.transpose(data_min_orig) \n",
    "\n",
    "        ## STEP 2: WHITEN\n",
    "        C_inv = None\n",
    "        C     = np.cov(T_maj) # the covariance matrix - of the majority class\n",
    "\n",
    "        # CALCULATE THE RANK OF THE MAJORITY CLASS DATA MATRIX AND INVERT IT IF POSSIBLE\n",
    "        data_rank = np.linalg.matrix_rank(data_maj_orig) \n",
    "        if data_rank < T_maj.shape[0]: # there are linearly dependent column, so inverse will be singular\n",
    "            if self.subSpaceSampling == False:\n",
    "                print(\"The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\")\n",
    "                return data, labels\n",
    "            else:\n",
    "\n",
    "                QR = np.linalg.qr(data_maj_orig)\n",
    "                indep = QR[1].diagonal() > 0\n",
    "                data = data[:,indep]\n",
    "                print(\"The majority class has linearly dependent columns. Resampled data will be in the \" + str(sum(indep==True)) + \" independent columns of the orginal \" + str(data_maj_orig.shape[1]) + \"-dimensional data.\")\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                C_inv = np.linalg.inv(C) # inverse of the covariance matrix\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if 'Singular matrix' in str(e):\n",
    "                    print(\"Majority class data is singular. Degrading to random oversampling with Gaussian jitter\")\n",
    "                    X_new = data_min_orig[np.random.choice(data_min_orig.shape[0], numSamples, replace=True), :]\n",
    "                    X_new = X_new + (0.1 * np.random.normal(0, data_maj_orig.std(0), X_new.shape))\n",
    "                    y_new = np.repeat(self.minClass, numSamples)\n",
    "                    data   = X_new\n",
    "                    labels = y_new\n",
    "                    return data, labels\n",
    "        \n",
    "        try:\n",
    "            M     = _msqrt(C_inv) # C_inv is the inverse of the covariance matrix, and M is the matrix for the whitening transform\n",
    "            M_inv = np.linalg.inv(M) # this is the inverse of the M matrix, we'll use it for getting the data back.\n",
    "\n",
    "            W_min      = M.dot(T_min) # whitening transform - whiten the minority class\n",
    "            W_maj      = M.dot(T_maj) # whitening transform - whiten the majority class\n",
    "        except:\n",
    "            print(\"value excpetion... synthetic instances not generated\")\n",
    "            return data, labels\n",
    "\n",
    "        ## STEP 3: FIND THE MEANS AND FEATURE BOUNDS TO USE IN THE GENERATION PROCESS\n",
    "        min_means  = W_min.mean(1)\n",
    "        min_stds   = W_min.std(1)\n",
    "        min_ranges_bottom = min_means - self.sd*min_stds\n",
    "        min_ranges_top    = min_means + self.sd*min_stds\n",
    "\n",
    " \n",
    "        ## STEP 4: GENERATE SYNTHETIC INSTANCES\n",
    "        # RANDOMLY REPLICATE THE WHITENED MINORITY CLASS INSTNACES <numSamples> TIMES TO GENERATE SYNTHETIC INSTANCES FROM\n",
    "        smpInitPts = W_min[:, np.random.choice(W_min.shape[1], numSamples)]\n",
    "        for smpInd in range(smpInitPts.shape[1]): # repeat \"times\" times, so we get a balanced dataset\n",
    "            new_w_raw = []\n",
    "            new       = None\n",
    "            new_w     = None\n",
    "            smp       = smpInitPts[:, smpInd]\n",
    "            for dim in range(len(min_means)):\n",
    "                new_w_raw.append(random.uniform(smp[dim]-self.sd*min_stds[dim], smp[dim]+self.sd*min_stds[dim]))\n",
    "\n",
    "            ## Step 5: SCALE BACK TO THE ORIGINAL SPACE\n",
    "            new_w = np.array(new_w_raw) / ((np.linalg.norm(new_w_raw)/np.linalg.norm(smp)))\n",
    "            new   = M_inv.dot(np.array(new_w))\n",
    "               \n",
    "            syntheticInstances.append(new)\n",
    "            \n",
    "        new_data   = np.array(syntheticInstances)\n",
    "        new_labels = [self.minClass]*len(syntheticInstances)\n",
    "\n",
    "        return new_data, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rTVFilIZa4PX"
   },
   "outputs": [],
   "source": [
    "def SWIM_sampling (data, imbalance, seed, num_classes):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  X_train_scaled_new = deepcopy(X_train_scaled)\n",
    "  y_train_new = deepcopy(y_train)\n",
    "  for i in range(1, num_classes):\n",
    "    numSamples = np.sum(y_train==0)-np.sum(y_train==i)\n",
    "    label = np.array(y_train[(y_train==0)|(y_train==i)])\n",
    "    data = np.array(X_train_scaled[(y_train==0)|(y_train==i)])\n",
    "    sw = SwimMaha(sd= 2, minClass=i)\n",
    "    data_new, new_labels = sw.mahaSampling(data, label, numSamples)\n",
    "    X_train_scaled_new = np.concatenate([X_train_scaled_new, data_new])\n",
    "    y_train_new = np.append(y_train_new, new_labels)\n",
    "  \n",
    "  return X_train_scaled_new, X_test_scaled, y_train_new, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7jEW-QTuKaSD"
   },
   "outputs": [],
   "source": [
    "class SingularMatrixException(Exception):\n",
    "    def __init__(self):\n",
    "        Exception.__init__(self,\"Singular data matrix... use subspace\") \n",
    "\n",
    "class MAHAKIL(object):\n",
    "    def __init__(self, pfp=0.5):\n",
    "        self.data_t = None  # Save the initial defect sample\n",
    "        self.pfp = pfp  # Proportion of expected defect samples\n",
    "        self.T = 0  # Number of defect samples to be generated\n",
    "        self.new = []  # Store newly generated samples\n",
    "\n",
    "    # Core method\n",
    "    # return : data_new, label_new\n",
    "    def fit_sample(self, data, label, num_classes):\n",
    "        \n",
    "        for i in range(1, num_classes):\n",
    "            \n",
    "            label_f = np.array(label[label==0])\n",
    "            label_t = np.array(label[label== i])\n",
    "            \n",
    "            data_f = np.array(data[label==0])\n",
    "            data_t = np.array(data[label== i])\n",
    "            \n",
    "            data_t = data_t+0.00001*np.random.rand((data_t.shape)[0],(data_t.shape)[1])\n",
    "            self.T = int(len(data_f) / (1 - self.pfp) - len(data_f))\n",
    "            self.data_t = np.array(data_t)\n",
    "            \n",
    "            # Calculate the Mahalanobis distance\n",
    "            d = 0\n",
    "            d = self.mahalanobis_distance(self.data_t)\n",
    "        \n",
    "            d = pd.DataFrame (d,columns=['Malhabonis Distance'])\n",
    "            d = d.reset_index(drop=False)\n",
    "            d = d.values.tolist()\n",
    "        \n",
    "\n",
    "            # Descending order\n",
    "            d.sort(key=lambda x: x[1], reverse=True)\n",
    "            # Divide the set of positive examples into two\n",
    "            k = len(d)\n",
    "            d_index = [d[i][0] for i in range(k)]\n",
    "            d_index = [ int(d) for d in d_index ]\n",
    "            data_t_sorted = [data_t[i] for i in d_index]\n",
    "            \n",
    "            mid = int(k/2)\n",
    "            bin1 = [data_t_sorted[i] for i in range(0, mid)]\n",
    "            bin2 = [data_t_sorted[i] for i in range(mid, k)]\n",
    "            # Loop iteration to generate new samples\n",
    "            l_ = len(bin1)\n",
    "            mark = [1, 3, 7, 15, 31, 63, 127, 255, 511, 1023, 2047, 4095, 8191, 16383, 32767, 65535, 131071, 262143, 524287]\n",
    "            p = self.T / (l_ +0.0)\n",
    "            is_full = True\n",
    "            g = mark.index([m for m in mark if m > p][0]) + 1\n",
    "            cluster = 2 ** (g - 1)  # Number of children of the last generation\n",
    "            if (self.T - mark[g-2]*l_) < cluster:\n",
    "                # Explain that adding more generations is better than keeping a few\n",
    "                is_full = False\n",
    "                g -= 1\n",
    "                k = 0\n",
    "            else:\n",
    "                k = l_ - round((self.T - mark[g-2]*l_)/cluster)\n",
    "            self.generate_new_sample(bin1, bin2, g, l_, k, is_full)\n",
    "            # Return data and labels\n",
    "            label_new = np.ones(len(self.new))+ (i-1)\n",
    "            data = np.append(data, self.new, axis=0)\n",
    "            data = pd.DataFrame(data)\n",
    "            label = np.append(label, label_new, axis=0)\n",
    "        return data, label \n",
    "\n",
    "    def mahalanobis_distance(self, x):\n",
    "        x_mu = x - np.mean(x)\n",
    "        cov = np.cov(x.T)\n",
    "        inv_covmat = np.linalg.inv(cov)\n",
    "        left = np.dot(x_mu, inv_covmat)\n",
    "        mahal = np.dot(left, x_mu.T).diagonal()\n",
    "        return mahal\n",
    "\n",
    "\n",
    "    # Generate new samples\n",
    "    def generate_new_sample(self, bin1, bin2, g, l, k, is_full):\n",
    "        # bin1, bin2 are arrays\n",
    "        # g Hereditary remaining algebra\n",
    "        # l bin1 number of items\n",
    "        # k The number of each node to be cropped in the last generation\n",
    "        # is_full whether it overflows, that is, the last generation is counted, whether it exceeds T, or is not full\n",
    "        assert len(bin1) <= len(bin2)\n",
    "        if g >= 2 or (g == 1 and is_full is False):\n",
    "            lv_0 = []  # Offspring\n",
    "            for i in range(l):\n",
    "                # Generate children\n",
    "                lv_0.append(np.mean(np.append(np.atleast_2d(bin1[i]), np.atleast_2d(bin2[i]), axis=0), axis=0))\n",
    "            self.new.extend(lv_0)\n",
    "            self.generate_new_sample(lv_0, bin1, g-1, l, k, is_full)\n",
    "            self.generate_new_sample(lv_0, bin2, g-1, l, k, is_full)\n",
    "        if g == 1 and is_full:\n",
    "            lv_0 = []  # Offspring\n",
    "            for i in range(l):\n",
    "                # Generate children\n",
    "                lv_0.append(np.mean(np.append(np.atleast_2d(bin1[i]), np.atleast_2d(bin2[i]), axis=0), axis=0))\n",
    "            del lv_0[-1: (-k-1): -1]\n",
    "            self.new.extend(lv_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xtA3GN2Sa6ou"
   },
   "outputs": [],
   "source": [
    "def MAHAKIL_sampling (data, imbalance, seed, num_classes):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  mk = MAHAKIL(pfp=0.5)\n",
    "  X_train_scaled, y_train = mk.fit_sample(X_train_scaled, y_train, num_classes)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MDO_sampling (data, imbalance, seed, num_classes):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  mk = MAHAKIL(pfp=0.5)\n",
    "  X_train_scaled, y_train = mk.fit_sample(X_train_scaled, y_train, num_classes)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "onLRdNao8J1n"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def a_value(probabilities, zero_label=0, one_label=1):\n",
    "    # Obtain a list of the probabilities for the specified zero label class\n",
    "    expanded_points = []\n",
    "    for instance in probabilities:\n",
    "        if instance[0] == zero_label or instance[0] == one_label:\n",
    "            expanded_points.append((instance[0], instance[1],zero_label))\n",
    "    sorted_ranks = sorted(expanded_points, key=lambda x: x[1])\n",
    "\n",
    "    n0, n1, sum_ranks = 0, 0, 0\n",
    "    # Iterate through ranks and increment counters for overall count and ranks of class 0\n",
    "    for index, point in enumerate(sorted_ranks):\n",
    "        if point[0] == zero_label:\n",
    "            n0 += 1\n",
    "            sum_ranks += index + 1  # Add 1 as ranks are one-based\n",
    "        elif point[0] == one_label:\n",
    "            n1 += 1\n",
    "        else:\n",
    "            pass  # Not interested in this class\n",
    "        if n0 ==0:\n",
    "          n0 = 1\n",
    "        if n1 == 0:\n",
    "          n1 = 1\n",
    "\n",
    "\n",
    "    return (sum_ranks - (n0*(n0+1)/2.0)) / float(n0 * n1)  # Eqn 3\n",
    "\n",
    "def MAUC(data, num_classes):\n",
    "    # Find all pairwise comparisons of labels\n",
    "    class_pairs = [x for x in combinations(range(num_classes), 2)]\n",
    "\n",
    "    # Have to take average of A value with both classes acting as label 0 as this\n",
    "    # gives different outputs for more than 2 classes\n",
    "    sum_avals = 0\n",
    "    for pairing in class_pairs:\n",
    "        sum_avals += (a_value(data, zero_label=pairing[0], one_label=pairing[1]) +\n",
    "                      a_value(data, zero_label=pairing[1], one_label=pairing[0])) / 2.0\n",
    "\n",
    "    return sum_avals * (2 / float(num_classes * (num_classes-1)))  # Eqn 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rRIAtvKez30l"
   },
   "outputs": [],
   "source": [
    "def classifier_results (data, imbalance, sampling_method, model, seed):\n",
    "\n",
    "  num_classes = len(data['class'].value_counts())\n",
    "  \n",
    "  if sampling_method == 'none':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  if sampling_method == 'SMOTE':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = SMOTE_sampling (data, imbalance, seed)\n",
    "  \n",
    "  if sampling_method == 'SWIM':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = SWIM_sampling (data, imbalance, seed, num_classes)\n",
    "  \n",
    "  if sampling_method == 'MAHAKIL':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = MAHAKIL_sampling(data, imbalance, seed, num_classes)\n",
    "  \n",
    "  if sampling_method == 'MDO':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = MDO_sampling(data, imbalance, seed, num_classes)\n",
    "\n",
    "  if model == 'naive_bayes':\n",
    "    model_func = GaussianNB()\n",
    "\n",
    "  elif model == 'K_neighbours':\n",
    "    model_func = KNeighborsClassifier(n_neighbors=3)\n",
    "  \n",
    "  elif model == 'Random_forest':\n",
    "    model_func = RandomForestClassifier()\n",
    "  \n",
    "  elif model == 'SVM':\n",
    "    model_func = SVC(kernel='rbf', gamma=1, C=1, probability=True, decision_function_shape='ovo')\n",
    "\n",
    "  model_base = model_func\n",
    "  model_base.fit(X_train_scaled, y_train)\n",
    "\n",
    "  y_pred = model_base.predict(X_test_scaled)\n",
    "  y_pred_probs = model_base.predict_proba(X_test_scaled)\n",
    "\n",
    "  probabilities = []\n",
    "  for i in range(len(y_pred)):\n",
    "    element = (y_pred_probs[i])\n",
    "    element = np.insert(element, 0, y_pred[i])\n",
    "    probabilities.append(element)\n",
    "  \n",
    "  score_MAUC = MAUC(probabilities, num_classes)\n",
    "\n",
    "  f1 = f1_score(y_test, y_pred, average=None)\n",
    "  score_f1 = sum(f1[1:])/ (len(f1)-1)\n",
    "  GMS = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "\n",
    "\n",
    "  return [data.name, imbalance, sampling_method, model, score_f1, score_MAUC, GMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier_results(retail_new, 'none', 'MDO','naive_bayes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Retail - new',\n",
       " 'none',\n",
       " 'SWIM',\n",
       " 'naive_bayes',\n",
       " 0.43254517510333595,\n",
       " 0.49994055360159956,\n",
       " 0.6752426915434973]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Retail - new',\n",
       " 'none',\n",
       " 'none',\n",
       " 'naive_bayes',\n",
       " 0.43215869264052736,\n",
       " 0.49994013413906596,\n",
       " 0.6746967761676528]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Retail - new',\n",
       " 'none',\n",
       " 'SMOTE',\n",
       " 'naive_bayes',\n",
       " 0.38730789342376387,\n",
       " 0.4999334597543541,\n",
       " 0.6436038034955949]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Retail - new',\n",
       " 'none',\n",
       " 'MDO',\n",
       " 'naive_bayes',\n",
       " 0.3596657693875504,\n",
       " 0.4999447321400773,\n",
       " 0.6174721794083832]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "B_Mn6FqJjv8k"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WineW3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-938cc2a064ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mWineW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWineR3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWineW5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWineR5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecoli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimbalance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'extreme'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msampling_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SMOTE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAHAKIL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SWIM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MDO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'naive_bayes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Random_forest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WineW3' is not defined"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "datasets = [WineW3, WineR3, vowel_3, WineW5, WineR5, ecoli, heart, glass]\n",
    "imbalance = ['none','high','extreme']\n",
    "sampling_method = ['none','SMOTE', 'MAHAKIL','SWIM', 'MDO']\n",
    "models = ['naive_bayes', 'Random_forest']\n",
    "for data in datasets:\n",
    "  for i in imbalance: \n",
    "    for s in sampling_method:\n",
    "      for m in models:\n",
    "        for seed in range(3):\n",
    "          try:\n",
    "            results = classifier_results (data, i, s, m, seed) \n",
    "            all_results.append(results)\n",
    "          except:\n",
    "            pass\n",
    "\n",
    "df = pd.DataFrame(all_results, columns=['Data', 'Imbalance_level','Sampling_method', 'Model', 'F1', 'MAUC', 'G_mean'])\n",
    "df.to_csv('multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Imbalance_level</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.561472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.561472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.561472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.417467</td>\n",
       "      <td>0.452179</td>\n",
       "      <td>0.625266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.445628</td>\n",
       "      <td>0.455872</td>\n",
       "      <td>0.637041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Data Imbalance_level Sampling_method          Model  \\\n",
       "0  Wine white - 3 class            none            none    naive_bayes   \n",
       "1  Wine white - 3 class            none            none    naive_bayes   \n",
       "2  Wine white - 3 class            none            none    naive_bayes   \n",
       "3  Wine white - 3 class            none            none  Random_forest   \n",
       "4  Wine white - 3 class            none            none  Random_forest   \n",
       "\n",
       "         F1      MAUC    G_mean  \n",
       "0  0.184659  0.486920  0.561472  \n",
       "1  0.184659  0.486920  0.561472  \n",
       "2  0.184659  0.486920  0.561472  \n",
       "3  0.417467  0.452179  0.625266  \n",
       "4  0.445628  0.455872  0.637041  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('multi.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "kq0v0moHdSeu",
    "outputId": "c31c7cad-9a42-4900-dde5-de3da6c70074"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>Imbalance_level</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>extreme</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>extreme</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>high</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>high</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>extreme</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>high</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>high</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Data Sampling_method Imbalance_level          Model  \\\n",
       "0                 Ecoli 1         MAHAKIL         extreme  Random_forest   \n",
       "1                 Ecoli 1         MAHAKIL         extreme    naive_bayes   \n",
       "2                 Ecoli 1         MAHAKIL            high  Random_forest   \n",
       "3                 Ecoli 1         MAHAKIL            high    naive_bayes   \n",
       "4                 Ecoli 1         MAHAKIL            none  Random_forest   \n",
       "..                    ...             ...             ...            ...   \n",
       "223  Wine white - 5 class            none         extreme    naive_bayes   \n",
       "224  Wine white - 5 class            none            high  Random_forest   \n",
       "225  Wine white - 5 class            none            high    naive_bayes   \n",
       "226  Wine white - 5 class            none            none  Random_forest   \n",
       "227  Wine white - 5 class            none            none    naive_bayes   \n",
       "\n",
       "        F1   MAUC  G_mean  \n",
       "0    0.723  0.418   0.871  \n",
       "1    0.432  0.334   0.746  \n",
       "2    0.656  0.409   0.851  \n",
       "3    0.433  0.412   0.767  \n",
       "4    0.806  0.404   0.900  \n",
       "..     ...    ...     ...  \n",
       "223  0.081  0.351   0.440  \n",
       "224  0.226  0.445   0.508  \n",
       "225  0.191  0.478   0.498  \n",
       "226  0.540  0.470   0.689  \n",
       "227  0.309  0.369   0.557  \n",
       "\n",
       "[228 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.groupby(\n",
    "   ['Data','Sampling_method','Imbalance_level', 'Model']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'MAUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "test = test.reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>Imbalance_level</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>high</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>none</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>high</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>high</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>none</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>high</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Data Sampling_method Imbalance_level     F1   MAUC  \\\n",
       "0                 Ecoli 1         MAHAKIL         extreme  0.723  0.418   \n",
       "1                 Ecoli 1         MAHAKIL            high  0.656  0.412   \n",
       "2                 Ecoli 1         MAHAKIL            none  0.806  0.404   \n",
       "3                 Ecoli 1             MDO         extreme  0.748  0.408   \n",
       "4                 Ecoli 1             MDO            high  0.682  0.412   \n",
       "..                    ...             ...             ...    ...    ...   \n",
       "110  Wine white - 5 class            SWIM            high  0.304  0.495   \n",
       "111  Wine white - 5 class            SWIM            none  0.492  0.494   \n",
       "112  Wine white - 5 class            none         extreme  0.081  0.351   \n",
       "113  Wine white - 5 class            none            high  0.226  0.478   \n",
       "114  Wine white - 5 class            none            none  0.540  0.470   \n",
       "\n",
       "     G_mean  \n",
       "0     0.871  \n",
       "1     0.851  \n",
       "2     0.900  \n",
       "3     0.877  \n",
       "4     0.837  \n",
       "..      ...  \n",
       "110   0.624  \n",
       "111   0.724  \n",
       "112   0.440  \n",
       "113   0.508  \n",
       "114   0.689  \n",
       "\n",
       "[115 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = test.groupby(\n",
    "   ['Data','Sampling_method','Imbalance_level']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"max\",  \n",
    "         'MAUC': 'max',\n",
    "         'G_mean': \"max\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "test2 = test2.reset_index()\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "Iy8R7KGDghK3",
    "outputId": "95cdf936-e8c3-4acf-a215-22d7a8055871"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.851</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.837</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.854</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.871</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>none</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.849</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.748</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.650</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.794</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.808</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>none</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.711</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.476</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.475</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.496</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.441</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>none</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.498</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.888</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.864</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.919</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.961</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>none</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.807</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.593</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.593</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.605</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.652</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.551</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.651</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.653</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.679</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.749</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.627</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.538</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.538</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.582</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.624</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.508</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Data Sampling_method     F1   MAUC  G_mean Dataset\n",
       "0                Ecoli 1         MAHAKIL  0.656  0.412   0.851      D1\n",
       "1                Ecoli 1             MDO  0.682  0.412   0.837      D1\n",
       "2                Ecoli 1           SMOTE  0.719  0.408   0.854      D1\n",
       "3                Ecoli 1            SWIM  0.736  0.408   0.871      D1\n",
       "4                Ecoli 1            none  0.676  0.411   0.849      D1\n",
       "5                Glass 1         MAHAKIL  0.580  0.266   0.748      D2\n",
       "6                Glass 1             MDO  0.433  0.244   0.650      D2\n",
       "7                Glass 1           SMOTE  0.652  0.287   0.794      D2\n",
       "8                Glass 1            SWIM  0.666  0.309   0.808      D2\n",
       "9                Glass 1            none  0.545  0.265   0.711      D2\n",
       "10               Heart 1         MAHAKIL  0.121  0.311   0.476      D3\n",
       "11               Heart 1             MDO  0.149  0.277   0.475      D3\n",
       "12               Heart 1           SMOTE  0.144  0.326   0.496      D3\n",
       "13               Heart 1            SWIM  0.138  0.328   0.441      D3\n",
       "14               Heart 1            none  0.182  0.405   0.498      D3\n",
       "15     Vowel - 3 classes         MAHAKIL  0.832  0.471   0.888      D4\n",
       "16     Vowel - 3 classes             MDO  0.793  0.471   0.864      D4\n",
       "17     Vowel - 3 classes           SMOTE  0.890  0.479   0.919      D4\n",
       "18     Vowel - 3 classes            SWIM  0.806  0.486   0.961      D4\n",
       "19     Vowel - 3 classes            none  0.742  0.465   0.807      D4\n",
       "20    Wine red - 3 class         MAHAKIL  0.083  0.491   0.593      D5\n",
       "21    Wine red - 3 class             MDO  0.083  0.491   0.593      D5\n",
       "22    Wine red - 3 class           SMOTE  0.220  0.492   0.605      D5\n",
       "23    Wine red - 3 class            SWIM  0.160  0.490   0.652      D5\n",
       "24    Wine red - 3 class            none  0.125  0.452   0.551      D5\n",
       "25  Wine white - 3 class         MAHAKIL  0.393  0.498   0.651      D6\n",
       "26  Wine white - 3 class             MDO  0.396  0.498   0.653      D6\n",
       "27  Wine white - 3 class           SMOTE  0.402  0.497   0.679      D6\n",
       "28  Wine white - 3 class            SWIM  0.309  0.496   0.749      D6\n",
       "29  Wine white - 3 class            none  0.419  0.487   0.627      D6\n",
       "30  Wine white - 5 class         MAHAKIL  0.310  0.493   0.538      D7\n",
       "31  Wine white - 5 class             MDO  0.306  0.494   0.538      D7\n",
       "32  Wine white - 5 class           SMOTE  0.296  0.495   0.582      D7\n",
       "33  Wine white - 5 class            SWIM  0.304  0.495   0.624      D7\n",
       "34  Wine white - 5 class            none  0.226  0.478   0.508      D7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = test2.copy(deep=True)\n",
    "high = group[(group['Imbalance_level']== 'high')]\n",
    "high = high.groupby(\n",
    "   ['Data','Sampling_method']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'MAUC': 'mean',\n",
    "         'G_mean': 'mean'  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "high = high.reset_index()\n",
    "high['Dataset']= high['Data']\n",
    "high['Dataset']= high['Dataset'].replace({'Ecoli 1': 'D1', 'Glass 1': 'D2', 'Heart 1': 'D3', 'Vowel - 3 classes': 'D4', 'Wine red - 3 class':'D5', 'Wine white - 3 class':'D6', 'Wine white - 5 class':'D7'})\n",
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_csv = high[['Dataset','Sampling_method','F1','MAUC','G_mean']]\n",
    "high_csv.head()\n",
    "high_csv.to_csv('multi_high.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww1pC5eJBsW_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/content/drive/MyDrive/Comparison_datasets.json\")\n",
    "df = df.replace({'none': 'None', 'high': 'High', 'extreme':'Extreme', 'absolute':'Absolute'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwyohXdLUWjl"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuXiJezeHrRq"
   },
   "outputs": [],
   "source": [
    "group = df.copy(deep=True)\n",
    "high = group[(group['Imbalance_level']== 'High')]\n",
    "high = high.groupby(\n",
    "   ['Sampling_method', 'Data']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'AUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "high = high.reset_index()\n",
    "high = high.sort_values(by=['Data', 'Sampling_method'])\n",
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbHqgvzHH6Nd"
   },
   "outputs": [],
   "source": [
    "group = df.copy(deep=True)\n",
    "extreme = group[(group['Imbalance_level']== 'High')]\n",
    "extreme = extreme.groupby(\n",
    "   ['Sampling_method', 'Data']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'AUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "extreme = extreme.reset_index()\n",
    "extreme = extreme.sort_values(by=['Data', 'Sampling_method'])\n",
    "extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnoUTZiZIIEY"
   },
   "outputs": [],
   "source": [
    "group = df.copy(deep=True)\n",
    "absolute = group[(group['Imbalance_level']== 'High')]\n",
    "absolute = absolute.groupby(\n",
    "   ['Sampling_method', 'Data']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'AUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "absolute = absolute.reset_index()\n",
    "absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38g43F__EB53"
   },
   "outputs": [],
   "source": [
    "df[\"Imbalance_level/ Sampling method\"] = df[\"Imbalance_level\"] + \"/\" + df[\"Sampling_method\"]\n",
    "df[\"Imbalance_level/ Sampling method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5rt-KAVArta"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n",
    "fig.suptitle('F1 Model Score by Data Imbalance')\n",
    "high = df[(df['Imbalance_level']== 'High')]\n",
    "extreme = df[(df['Imbalance_level']== 'Extreme')]\n",
    "absolute = df[(df['Imbalance_level']== 'Absolute')]\n",
    "sns.boxplot(ax=axes[0], x=\"Model\", y=\"F1\", data=high, palette=\"mako\")\n",
    "axes[0].set_title(\"High Imbalance\")\n",
    "sns.boxplot(ax=axes[1], x=\"Model\", y=\"F1\", data=extreme, palette=\"mako\")\n",
    "axes[1].set_title(\"Extreme Imbalance\")\n",
    "sns.boxplot(ax=axes[2], x=\"Model\", y=\"F1\", data= absolute, palette=\"mako\")\n",
    "axes[2].set_title(\"Absolute Imbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2vkK8LtFevj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qd-wfXJhBbWw"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x=\"Imbalance_level/ Sampling method\", y=\"F1\", data=df, palette=\"mako\")\n",
    "plt.axvline(x=3.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=7.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=11.5, ymin=0, ymax=40000, color='black')\n",
    "plt.title('F1 score per sampling method - for three imbalance levels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdBAO-7eOBBo"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x=\"Imbalance_level/ Sampling method\", y=\"AUC\", data=df, palette=\"mako\")\n",
    "plt.axvline(x=3.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=7.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=11.5, ymin=0, ymax=40000, color='black')\n",
    "plt.title('AUC score per sampling method - for three imbalance levels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rCm11AJNJh_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x=\"Imbalance_level/ Sampling method\", y=\"G_mean\", data=df, palette=\"mako\")\n",
    "plt.axvline(x=3.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=7.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=11.5, ymin=0, ymax=40000, color='black')\n",
    "plt.title('Geometric mean score per sampling method - for three imbalance levels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1U7UHHdGNS90"
   },
   "outputs": [],
   "source": [
    "import multi_imbalance.resampling.mdo as sample_mdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASgYOYxZEz8r"
   },
   "outputs": [],
   "source": [
    " !pip install multi_imbalance"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Emma Diss Re-write - multi.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
