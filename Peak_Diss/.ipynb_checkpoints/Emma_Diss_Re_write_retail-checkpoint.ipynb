{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62iiPEpGdPsC",
    "outputId": "27b7c388-8438-4f73-99c5-d56e0e9a940c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from random import randint \n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, plot_confusion_matrix, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from multi_imbalance.resampling.mdo import MDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zB7KgSFTfciI"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z-qnMTUjaXJ-"
   },
   "outputs": [],
   "source": [
    "wine_white = pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "wine_red = pd.read_csv('winequality-red.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCfLZhz8HM2N",
    "outputId": "da22d279-dfe8-4798-fb30-31214a52c067"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9       5\n",
       "8     175\n",
       "7     880\n",
       "6    2198\n",
       "5    1457\n",
       "4     163\n",
       "3      20\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_white['quality'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPhuBjrdC1JB",
    "outputId": "c69dacfc-246f-4b39-8774-71c8b7598008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4535\n",
       "2     183\n",
       "1     180\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineW3 = deepcopy(wine_white)\n",
    "WineW3[\"class\"] = \"\"\n",
    "WineW3.loc[WineW3.quality >= 8, \"class\"] = 1\n",
    "WineW3.loc[((WineW3.quality == 7), \"class\")] = 0\n",
    "WineW3.loc[((WineW3.quality == 6), \"class\")] = 0\n",
    "WineW3.loc[((WineW3.quality == 5), \"class\")] = 0\n",
    "WineW3.loc[WineW3.quality <= 4, \"class\"] = 2\n",
    "WineW3['class'] = WineW3['class'].astype(\"category\")\n",
    "WineW3 = WineW3.drop(columns=['quality'])\n",
    "WineW3.name = 'Wine white - 3 class'\n",
    "WineW3['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLPMF82MISca",
    "outputId": "bc9994a0-d153-41e6-a63c-b2179a7dab2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2198\n",
       "4    1457\n",
       "3     880\n",
       "2     183\n",
       "1     180\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineW5 = deepcopy(wine_white)\n",
    "WineW5[\"class\"] = \"\"\n",
    "WineW5.loc[WineW5.quality >= 8, \"class\"] = 1\n",
    "WineW5.loc[((WineW5.quality == 7), \"class\")] = 3\n",
    "WineW5.loc[((WineW5.quality == 6), \"class\")] = 0\n",
    "WineW5.loc[((WineW5.quality == 5), \"class\")] = 4\n",
    "WineW5.loc[WineW5.quality <= 4, \"class\"] = 2\n",
    "WineW5['class'] = WineW5['class'].astype(\"category\")\n",
    "WineW5 = WineW5.drop(columns=['quality'])\n",
    "WineW5.name = 'Wine white - 5 class'\n",
    "WineW5['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSsIvFQ7aag6",
    "outputId": "54ece8c8-11fa-4ae6-fc8d-2ed95e48310c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3655\n",
       "1    1060\n",
       "2     163\n",
       "3      20\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineW4 = deepcopy(wine_white)\n",
    "WineW4[\"class\"] = \"\"\n",
    "WineW4.loc[WineW4.quality >= 7, \"class\"] = 1\n",
    "WineW4.loc[WineW4.quality == 6, \"class\"] = 0\n",
    "WineW4.loc[WineW4.quality == 5, \"class\"] = 0\n",
    "WineW4.loc[WineW4.quality == 4, \"class\"] = 2\n",
    "WineW4.loc[WineW4.quality <= 3, \"class\"] = 3\n",
    "WineW4['class'] = WineW4['class'].astype(\"category\")\n",
    "WineW4 = WineW4.drop(columns=['quality'])\n",
    "WineW4.name = 'Wine white - 4 class'\n",
    "WineW4['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4AugjdXacvF",
    "outputId": "e4038751-bdf4-4ef1-ac91-abdd7895dc69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     18\n",
       "7    199\n",
       "6    638\n",
       "5    681\n",
       "4     53\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_red['quality'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iF3T2GrhDRgv",
    "outputId": "7a2fadcb-d999-43ff-fb67-dddd4221c073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1518\n",
       "2      63\n",
       "1      18\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineR3 = deepcopy(wine_red)\n",
    "WineR3[\"class\"] = \"\"\n",
    "WineR3.loc[WineR3.quality >= 8, \"class\"] = 1\n",
    "WineR3.loc[((WineR3.quality == 7), \"class\")] = 0\n",
    "WineR3.loc[((WineR3.quality == 6), \"class\")] = 0\n",
    "WineR3.loc[((WineR3.quality == 5), \"class\")] = 0\n",
    "WineR3.loc[WineR3.quality <= 4, \"class\"] = 2\n",
    "WineR3['class'] = WineR3['class'].astype(\"category\")\n",
    "WineR3 = WineR3.drop(columns=['quality'])\n",
    "WineR3.name = 'Wine red - 3 class'\n",
    "WineR3['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pXUhm_6nbNe",
    "outputId": "84b992e1-59f6-41c1-d4ad-18ea49be4bdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    681\n",
       "4    638\n",
       "3    199\n",
       "2     63\n",
       "1     18\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineR5 = deepcopy(wine_red)\n",
    "WineR5[\"class\"] = \"\"\n",
    "WineR5.loc[WineR5.quality >= 8, \"class\"] = 1\n",
    "WineR5.loc[((WineR5.quality == 7), \"class\")] = 3\n",
    "WineR5.loc[((WineR5.quality == 6), \"class\")] = 4\n",
    "WineR5.loc[((WineR5.quality == 5), \"class\")] = 0\n",
    "WineR5.loc[WineR5.quality <= 4, \"class\"] = 2\n",
    "WineR5['class'] = WineR5['class'].astype(\"category\")\n",
    "WineR5 = WineR5.drop(columns=['quality'])\n",
    "WineR5.name = 'Wine red - 5 class'\n",
    "WineR5['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WF-ASW1BM9jJ",
    "outputId": "bc3fa5b1-5a3d-4ef8-e094-2ff879b188cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1319\n",
       "1     217\n",
       "2      53\n",
       "3      10\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineR4 = deepcopy(wine_red)\n",
    "WineR4[\"class\"] = \"\"\n",
    "WineR4.loc[WineR4.quality >= 7, \"class\"] = 1\n",
    "WineR4.loc[WineR4.quality == 6, \"class\"] = 0\n",
    "WineR4.loc[WineR4.quality == 5, \"class\"] = 0\n",
    "WineR4.loc[WineR4.quality == 4, \"class\"] = 2\n",
    "WineR4.loc[WineR4.quality <= 3, \"class\"] = 3\n",
    "WineR4['class'] = WineR4['class'].astype(\"category\")\n",
    "WineR4 = WineR4.drop(columns=['quality'])\n",
    "WineR4.name = 'Wine red - 4 class'\n",
    "WineR4['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5xql-6ioy4z",
    "outputId": "92159f23-766d-4cce-85dd-cafe7f836c63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1536\n",
       "1      63\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low Quality Red Wine (3,4)\n",
    "WineRL = deepcopy(wine_red)\n",
    "WineRL[\"class\"] = \"\"\n",
    "WineRL.loc[WineRL.quality >= 5, \"class\"] = 0\n",
    "WineRL.loc[WineRL.quality <= 4, \"class\"] = 1\n",
    "WineRL['class'] = WineRL['class'].astype(\"category\")\n",
    "WineRL = WineRL.drop(columns=['quality'])\n",
    "WineRL.name = 'D11 - Wine_red_low'\n",
    "WineRL['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SgaEXmOJagWJ"
   },
   "outputs": [],
   "source": [
    "vowel = pd.read_csv('vowel_data.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J6ytm0mtaiS8"
   },
   "outputs": [],
   "source": [
    "vowel = vowel.drop(columns=[10])\n",
    "vowel = vowel.dropna()\n",
    "cols_to_check = [0,9]\n",
    "vowel[cols_to_check] = vowel[cols_to_check].replace({'{':''}, regex=True)\n",
    "vowel[cols_to_check] = vowel[cols_to_check].replace({'}':''}, regex=True)\n",
    "vowel = vowel.reset_index(drop=True)\n",
    "vowel[9] = pd.to_numeric(vowel[9])\n",
    "vowel = vowel.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "qW6TTEC4OVmi",
    "outputId": "aac30b77-d779-4539-9ce7-0bea9ccc7bbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.639</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>1.779</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>1.627</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.327</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>1.365</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>1.933</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>-0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.120</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-1.576</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>1.559</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.287</td>\n",
       "      <td>1.809</td>\n",
       "      <td>-1.498</td>\n",
       "      <td>1.012</td>\n",
       "      <td>-1.053</td>\n",
       "      <td>1.060</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.598</td>\n",
       "      <td>1.938</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>1.062</td>\n",
       "      <td>-1.633</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9\n",
       "0 -3.639  0.418 -0.670  1.779 -0.168  1.627 -0.388  0.529 -0.874 -0.814\n",
       "1 -3.327  0.496 -0.694  1.365 -0.265  1.933 -0.363  0.510 -0.621 -0.488\n",
       "2 -2.120  0.894 -1.576  0.147 -0.707  1.559 -0.579  0.676 -0.809 -0.049\n",
       "3 -2.287  1.809 -1.498  1.012 -1.053  1.060 -0.567  0.235 -0.091 -0.795\n",
       "4 -2.598  1.938 -0.846  1.062 -1.633  0.764  0.394 -0.150  0.277 -0.396"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ilmKyRKrall-"
   },
   "outputs": [],
   "source": [
    "speakers = ['Andrew', 'Bill', 'David', 'Mark', 'Jo', 'Kate', 'Penny', 'Rose', 'Mike', 'Nick', 'Rich', 'Tim', 'Sarah', 'Sue', 'Wendy']\n",
    "words = ['hid', 'hId', 'hEd', 'hAd', 'hYd', 'had', 'hOd', 'hod', 'hUd', 'hud', 'hed']\n",
    "segments = [0,1,2,3,4,5]\n",
    "speakers_1 = []\n",
    "words_1 = []\n",
    "segment = []\n",
    "for s in speakers:\n",
    "  for se in segments:\n",
    "    for w in words:\n",
    "      speakers_1.append(s)\n",
    "      segment.append(se)\n",
    "      words_1.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sivKeb4LampC"
   },
   "outputs": [],
   "source": [
    "vowel['word'] = np.arange(len(vowel))\n",
    "vowel['speaker'] = np.arange(len(vowel))\n",
    "vowel['segment'] = np.arange(len(vowel))\n",
    "for l in range(len(vowel)):\n",
    "  vowel['speaker'] = vowel['speaker'].replace(l, speakers_1[l])\n",
    "  vowel['word'] = vowel['word'].replace(l, words_1[l])\n",
    "  vowel['segment'] = vowel['segment'].replace(l, segment[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3STWkqSOc8p",
    "outputId": "9aebd2f9-f565-496b-a79c-f04d05c93f3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hud    90\n",
       "hod    90\n",
       "hid    90\n",
       "hed    90\n",
       "had    90\n",
       "hYd    90\n",
       "hUd    90\n",
       "hOd    90\n",
       "hId    90\n",
       "hEd    90\n",
       "hAd    90\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel['word'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7psCi70aqdu",
    "outputId": "d362b35a-df12-4732-c7cd-db4b0ea4c490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    810\n",
       "1     90\n",
       "2     90\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel['class']= ''\n",
    "# Vowel 3\n",
    "vowel_3 = deepcopy(vowel)\n",
    "vowel_3.loc[vowel_3.word != 'hid', \"class\"] = 0\n",
    "vowel_3.loc[vowel_3.word == 'hid', \"class\"] = 1\n",
    "vowel_3.loc[vowel_3.word == 'hEd', \"class\"] = 2\n",
    "vowel_3['class'] = vowel_3['class'].astype(\"int\")\n",
    "vowel_3['class'] = vowel_3['class'].astype(\"category\")\n",
    "vowel_3 = vowel_3.drop(columns=['word','speaker','segment'])\n",
    "vowel_3.name = 'Vowel - 3 classes'\n",
    "vowel_3['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "vXwyp-CQmnnT",
    "outputId": "9254ac7d-6a82-4fb4-edf6-978e54b651f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3     4     5     6 cluster\n",
       "0  0.49  0.29  0.48  0.5  0.56  0.24  0.35      cp\n",
       "1  0.07  0.40  0.48  0.5  0.54  0.35  0.44      cp\n",
       "2  0.56  0.40  0.48  0.5  0.49  0.37  0.46      cp\n",
       "3  0.59  0.49  0.48  0.5  0.52  0.45  0.36      cp\n",
       "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35      cp"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoli = pd.read_csv('ecoli.csv', header=None)\n",
    "ecoli = ecoli.rename(columns={7:'cluster'})\n",
    "ecoli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prlh1I1DvmdL",
    "outputId": "93d2d7c2-09e2-4bac-dc3a-8a27f80a0964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp     143\n",
       "im      77\n",
       "pp      52\n",
       "imU     35\n",
       "om      20\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoli = ecoli[(ecoli['cluster']!= 'imL') & (ecoli['cluster']!= 'imS')&(ecoli['cluster']!= 'omL')]\n",
    "ecoli['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LybStq-qrIHy",
    "outputId": "5c4268fd-bf96-4361-dc55-3b6a0e966a7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143\n",
       "1     77\n",
       "2     52\n",
       "3     35\n",
       "4     20\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoli = deepcopy(ecoli)\n",
    "ecoli.loc[ecoli.cluster == 'cp', \"class\"] = 0\n",
    "ecoli.loc[ecoli.cluster == 'im', \"class\"] = 1\n",
    "ecoli.loc[ecoli.cluster == 'pp', \"class\"] = 2\n",
    "ecoli.loc[ecoli.cluster == 'imU', \"class\"] = 3\n",
    "ecoli.loc[ecoli.cluster == 'om', \"class\"] = 4\n",
    "ecoli.loc[ecoli.cluster == 'omL', \"class\"] = 5\n",
    "ecoli.loc[ecoli.cluster == 'imS', \"class\"] = 6\n",
    "ecoli.loc[ecoli.cluster == 'imL', \"class\"] = 7\n",
    "ecoli['class'] = ecoli['class'].astype(\"int\")\n",
    "ecoli['class'] = ecoli['class'].astype(\"category\")\n",
    "ecoli = ecoli.drop(columns=['cluster'])\n",
    "ecoli['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "m8xFWUZHvV8r",
    "outputId": "e84b291d-0e8f-4317-bb76-08227a7d051f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     4     5     6 class\n",
       "0  0.49  0.29  0.48  0.56  0.24  0.35     0\n",
       "1  0.07  0.40  0.48  0.54  0.35  0.44     0\n",
       "2  0.56  0.40  0.48  0.49  0.37  0.46     0\n",
       "3  0.59  0.49  0.48  0.52  0.45  0.36     0\n",
       "4  0.23  0.32  0.48  0.55  0.25  0.35     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoli = ecoli.drop(columns=3)\n",
    "ecoli.name = 'Ecoli 1'\n",
    "ecoli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZWgi0rDNX5lZ"
   },
   "outputs": [],
   "source": [
    "heart = pd.read_csv('processed.cleveland.data', header=None)\n",
    "heart = heart.rename(columns={13:'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SObbxcP78Qlb",
    "outputId": "7b25d6ca-7feb-4d26-c619-2e60a3c61d80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lmygTPHa5Y8g"
   },
   "outputs": [],
   "source": [
    "heart[11] = pd.to_numeric(heart[11], errors='coerce')\n",
    "heart[12] = pd.to_numeric(heart[12], errors='coerce')\n",
    "heart[11] = heart.groupby(\"class\").transform(lambda x: x.fillna(x.median()))\n",
    "heart[12] = heart.groupby(\"class\").transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ZJjBXe8o5vGL",
    "outputId": "76f51a38-df99-4b06-849b-ab8ac8e97bc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2      3      4    5    6      7    8    9   10    11    12  \\\n",
       "0  63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  63.0  63.0   \n",
       "1  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  67.0  67.0   \n",
       "2  67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  67.0  67.0   \n",
       "3  37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  37.0  37.0   \n",
       "4  41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  41.0  41.0   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      2  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.name = 'Heart 1'\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "a5iMTWVi9Zz7",
    "outputId": "85ee3917-743d-454d-ac10-5aafd314d12e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.657</td>\n",
       "      <td>2.33</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.741</td>\n",
       "      <td>4.43</td>\n",
       "      <td>31</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.743</td>\n",
       "      <td>4.33</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.944</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2      3      4      5     6   7   8  9  class\n",
       "0  5   7   35  1.400  0.400  0.657  2.33  14  23  6      0\n",
       "1  6   7   42  1.167  0.429  0.881  3.60  18  37  5      0\n",
       "2  6  18  108  3.000  0.287  0.741  4.43  31  80  7      0\n",
       "3  5   7   35  1.400  0.371  0.743  4.33  13  26  3      0\n",
       "4  6   3   18  0.500  0.500  0.944  2.25   9  17  4      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = pd.read_csv('page-blocks.data', header=None, delimiter='\\s+')\n",
    "page['class']=page[10]-1\n",
    "page = page.drop(columns={10})\n",
    "page.name = 'Page 1'\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMYiW0AM-EWN",
    "outputId": "404b6ff9-4608-4272-9905-0cf49be767d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4913\n",
       "1     329\n",
       "4     115\n",
       "3      88\n",
       "2      28\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fZbsZJziAD-b"
   },
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glass.data', header=None, delimiter=',', index_col=0)\n",
    "glass = glass.rename(columns={10:'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5vCSS8l8DAnO"
   },
   "outputs": [],
   "source": [
    "glass['class'] = glass['class'].map({2: 0, 7:2, 3:3, 5:4, 6:5, 1:1})\n",
    "glass['class'] = glass['class'].fillna(0.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ShYHtQRAZFX",
    "outputId": "e26fdae3-ac16-4524-d74b-1a527556985f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76\n",
       "1    70\n",
       "2    29\n",
       "3    17\n",
       "4    13\n",
       "5     9\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.name = 'Glass 1'\n",
    "glass['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "OsUspqauau3P"
   },
   "outputs": [],
   "source": [
    "# train test/ scaling\n",
    "def data_prep (data, seed):\n",
    "  X= data.drop('class',axis=1).copy()\n",
    "  y = data['class'].copy()\n",
    "  y = y.astype('category')\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed, shuffle=y, stratify=y) # add ssed\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train_scaled = scaler.transform(X_train)\n",
    "  X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "  X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n",
    "  X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SNuXHNsxyhaB"
   },
   "outputs": [],
   "source": [
    "def random_under_minority (data, imbalance_level, seed):\n",
    "  if imbalance_level == 'none':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data_prep(data, 1)\n",
    "    X_train_scaled = X_train_scaled.reset_index(drop=True).values\n",
    "    X_test_scaled = X_test_scaled.reset_index(drop=True).values\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "  \n",
    "  else:\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data_prep(data, 1)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    X_train_scaled['class'] = y_train\n",
    "\n",
    "    class_counts = X_train_scaled['class'].value_counts().to_frame()\n",
    "\n",
    "    minority_full = pd.DataFrame()\n",
    "    for c in range(1,len(class_counts)):\n",
    "      maj_count = class_counts.iloc[0,0]\n",
    "      min_count = class_counts.iloc[c,0]\n",
    "\n",
    "      majority = X_train_scaled[(X_train_scaled['class'] == 0)]\n",
    "      minority = X_train_scaled[(X_train_scaled['class']== c)]\n",
    "\n",
    "      if imbalance_level == 'absolute':\n",
    "          downsample = 6\n",
    "  \n",
    "      else:\n",
    "        if imbalance_level == 'high':\n",
    "          imbalance = 0.05\n",
    "      \n",
    "        elif imbalance_level == 'extreme':\n",
    "          imbalance = 0.01\n",
    "\n",
    "        downsample = (maj_count * imbalance).round().astype('int')\n",
    "    \n",
    "      if imbalance_level == 'extreme' and downsample < 8:\n",
    "        downsample = 8\n",
    "\n",
    "      if downsample < 6:\n",
    "        downsample = 6 \n",
    " \n",
    "      if downsample >= min_count:\n",
    "        minority_sample = minority\n",
    "      \n",
    "      \n",
    "      else:\n",
    "        minority_sample = minority.sample(n= downsample)\n",
    "\n",
    "      minority_full = pd.concat([minority_full, minority_sample])\n",
    "    final = pd.concat([majority, minority_full])\n",
    "    final = shuffle(final)\n",
    "\n",
    "    X_train_scaled = final.drop('class',axis=1).copy()\n",
    "    y_train = final['class'].copy()\n",
    "    y_train = y_train.astype('category')\n",
    "\n",
    "    X_train_scaled = X_train_scaled.reset_index(drop=True).values\n",
    "    X_test_scaled = X_test_scaled.reset_index(drop=True).values\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "z8NQNtO3a1dX"
   },
   "outputs": [],
   "source": [
    "def SMOTE_sampling (data, imbalance, seed):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  SMOTE_sample = SMOTE()\n",
    "  X_train_scaled, y_train = SMOTE_sample.fit_resample(X_train_scaled, y_train)\n",
    "  \n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nu5ULZ_KMl0B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "class SingularMatrixException(Exception):\n",
    "    def __init__(self):\n",
    "        Exception.__init__(self,\"Singular data matrix... use subspace\") \n",
    "\n",
    "def _msqrt(X):\n",
    "    '''Computes the square root matrix of symmetric square matrix X.'''\n",
    "    (L, V) = np.linalg.eig(X)\n",
    "    return V.dot(np.diag(np.sqrt(L))).dot(V.T) \n",
    "\n",
    "\n",
    "class SwimMaha:\n",
    "\n",
    "    def __init__(self, sd=0.25, minClass=None, subSpaceSampling=False):\n",
    "        self.sd = sd\n",
    "        self.minClass = minClass\n",
    "        self.subSpaceSampling = subSpaceSampling\n",
    "\n",
    "    # the data passed is transposed, so the rows are the features, and the columns are the instances\n",
    "    def mahaSampling(self, data, labels, numSamples):\n",
    "\n",
    "        if self.minClass == None:\n",
    "            self.minClass     = np.argmin(np.bincount(labels.astype(int)))\n",
    "\n",
    "        syntheticInstances  = []\n",
    "        data_maj_orig       = data[np.where(labels!=self.minClass)[0], :]\n",
    "        data_min_orig       = data[np.where(labels==self.minClass)[0], :]\n",
    "        data_min_orig = data_min_orig+0.0001*np.random.rand((data_min_orig.shape)[0],(data_min_orig.shape)[1])\n",
    "\n",
    "        if(np.sum(labels==self.minClass)==1):\n",
    "            data_min_orig = data_min_orig.reshape(1,len(data_min_orig))\n",
    "            # trnMinData    = trnMinData.reshape(1,len(trnMinData))\n",
    "\n",
    "        ## STEP 1: CENTRE\n",
    "        ## CENTRE THE MAJORITY CLASS AND CENTRE THE MINORITY CLASS WITH RESPECT TO THE MAJORITY CLASS\n",
    "        scaler = StandardScaler(with_std=False)\n",
    "        T_maj  = np.transpose(scaler.fit_transform(data_maj_orig))\n",
    "        T_min  = np.transpose(data_min_orig) \n",
    "\n",
    "        ## STEP 2: WHITEN\n",
    "        C_inv = None\n",
    "        C     = np.cov(T_maj) # the covariance matrix - of the majority class\n",
    "\n",
    "        # CALCULATE THE RANK OF THE MAJORITY CLASS DATA MATRIX AND INVERT IT IF POSSIBLE\n",
    "        data_rank = np.linalg.matrix_rank(data_maj_orig) \n",
    "        if data_rank < T_maj.shape[0]: # there are linearly dependent column, so inverse will be singular\n",
    "            if self.subSpaceSampling == False:\n",
    "                print(\"The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\")\n",
    "                return data, labels\n",
    "            else:\n",
    "\n",
    "                QR = np.linalg.qr(data_maj_orig)\n",
    "                indep = QR[1].diagonal() > 0\n",
    "                data = data[:,indep]\n",
    "                print(\"The majority class has linearly dependent columns. Resampled data will be in the \" + str(sum(indep==True)) + \" independent columns of the orginal \" + str(data_maj_orig.shape[1]) + \"-dimensional data.\")\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                C_inv = np.linalg.inv(C) # inverse of the covariance matrix\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if 'Singular matrix' in str(e):\n",
    "                    print(\"Majority class data is singular. Degrading to random oversampling with Gaussian jitter\")\n",
    "                    X_new = data_min_orig[np.random.choice(data_min_orig.shape[0], numSamples, replace=True), :]\n",
    "                    X_new = X_new + (0.1 * np.random.normal(0, data_maj_orig.std(0), X_new.shape))\n",
    "                    y_new = np.repeat(self.minClass, numSamples)\n",
    "                    data   = X_new\n",
    "                    labels = y_new\n",
    "                    return data, labels\n",
    "        \n",
    "        try:\n",
    "            M     = _msqrt(C_inv) # C_inv is the inverse of the covariance matrix, and M is the matrix for the whitening transform\n",
    "            M_inv = np.linalg.inv(M) # this is the inverse of the M matrix, we'll use it for getting the data back.\n",
    "\n",
    "            W_min      = M.dot(T_min) # whitening transform - whiten the minority class\n",
    "            W_maj      = M.dot(T_maj) # whitening transform - whiten the majority class\n",
    "        except:\n",
    "            print(\"value excpetion... synthetic instances not generated\")\n",
    "            return data, labels\n",
    "\n",
    "        ## STEP 3: FIND THE MEANS AND FEATURE BOUNDS TO USE IN THE GENERATION PROCESS\n",
    "        min_means  = W_min.mean(1)\n",
    "        min_stds   = W_min.std(1)\n",
    "        min_ranges_bottom = min_means - self.sd*min_stds\n",
    "        min_ranges_top    = min_means + self.sd*min_stds\n",
    "\n",
    " \n",
    "        ## STEP 4: GENERATE SYNTHETIC INSTANCES\n",
    "        # RANDOMLY REPLICATE THE WHITENED MINORITY CLASS INSTNACES <numSamples> TIMES TO GENERATE SYNTHETIC INSTANCES FROM\n",
    "        smpInitPts = W_min[:, np.random.choice(W_min.shape[1], numSamples)]\n",
    "        for smpInd in range(smpInitPts.shape[1]): # repeat \"times\" times, so we get a balanced dataset\n",
    "            new_w_raw = []\n",
    "            new       = None\n",
    "            new_w     = None\n",
    "            smp       = smpInitPts[:, smpInd]\n",
    "            for dim in range(len(min_means)):\n",
    "                new_w_raw.append(random.uniform(smp[dim]-self.sd*min_stds[dim], smp[dim]+self.sd*min_stds[dim]))\n",
    "\n",
    "            ## Step 5: SCALE BACK TO THE ORIGINAL SPACE\n",
    "            new_w = np.array(new_w_raw) / ((np.linalg.norm(new_w_raw)/np.linalg.norm(smp)))\n",
    "            new   = M_inv.dot(np.array(new_w))\n",
    "               \n",
    "            syntheticInstances.append(new)\n",
    "            \n",
    "        new_data   = np.array(syntheticInstances)\n",
    "        new_labels = [self.minClass]*len(syntheticInstances)\n",
    "\n",
    "        return new_data, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "rTVFilIZa4PX"
   },
   "outputs": [],
   "source": [
    "def SWIM_sampling (data, imbalance, seed, num_classes):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  X_train_scaled_new = deepcopy(X_train_scaled)\n",
    "  y_train_new = deepcopy(y_train)\n",
    "  for i in range(1, num_classes):\n",
    "    numSamples = np.sum(y_train==0)-np.sum(y_train==i)\n",
    "    label = np.array(y_train[(y_train==0)|(y_train==i)])\n",
    "    data = np.array(X_train_scaled[(y_train==0)|(y_train==i)])\n",
    "    sw = SwimMaha(sd= 2, minClass=i)\n",
    "    data_new, new_labels = sw.mahaSampling(data, label, numSamples)\n",
    "    X_train_scaled_new = np.concatenate([X_train_scaled_new, data_new])\n",
    "    y_train_new = np.append(y_train_new, new_labels)\n",
    "  \n",
    "  return X_train_scaled_new, X_test_scaled, y_train_new, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "7jEW-QTuKaSD"
   },
   "outputs": [],
   "source": [
    "class SingularMatrixException(Exception):\n",
    "    def __init__(self):\n",
    "        Exception.__init__(self,\"Singular data matrix... use subspace\") \n",
    "\n",
    "class MAHAKIL(object):\n",
    "    def __init__(self, pfp=0.5):\n",
    "        self.data_t = None  # Save the initial defect sample\n",
    "        self.pfp = pfp  # Proportion of expected defect samples\n",
    "        self.T = 0  # Number of defect samples to be generated\n",
    "        self.new = []  # Store newly generated samples\n",
    "\n",
    "    # Core method\n",
    "    # return : data_new, label_new\n",
    "    def fit_sample(self, data, label, num_classes):\n",
    "        \n",
    "        for i in range(1, num_classes):\n",
    "            \n",
    "            label_f = np.array(label[label==0])\n",
    "            label_t = np.array(label[label== i])\n",
    "            \n",
    "            data_f = np.array(data[label==0])\n",
    "            data_t = np.array(data[label== i])\n",
    "            \n",
    "            data_t = data_t+0.00001*np.random.rand((data_t.shape)[0],(data_t.shape)[1])\n",
    "            self.T = int(len(data_f) / (1 - self.pfp) - len(data_f))\n",
    "            self.data_t = np.array(data_t)\n",
    "            \n",
    "            # Calculate the Mahalanobis distance\n",
    "            d = 0\n",
    "            d = self.mahalanobis_distance(self.data_t)\n",
    "        \n",
    "            d = pd.DataFrame (d,columns=['Malhabonis Distance'])\n",
    "            d = d.reset_index(drop=False)\n",
    "            d = d.values.tolist()\n",
    "        \n",
    "\n",
    "            # Descending order\n",
    "            d.sort(key=lambda x: x[1], reverse=True)\n",
    "            # Divide the set of positive examples into two\n",
    "            k = len(d)\n",
    "            d_index = [d[i][0] for i in range(k)]\n",
    "            d_index = [ int(d) for d in d_index ]\n",
    "            data_t_sorted = [data_t[i] for i in d_index]\n",
    "            \n",
    "            mid = int(k/2)\n",
    "            bin1 = [data_t_sorted[i] for i in range(0, mid)]\n",
    "            bin2 = [data_t_sorted[i] for i in range(mid, k)]\n",
    "            # Loop iteration to generate new samples\n",
    "            l_ = len(bin1)\n",
    "            mark = [1, 3, 7, 15, 31, 63, 127, 255, 511, 1023, 2047, 4095, 8191, 16383, 32767, 65535, 131071, 262143, 524287]\n",
    "            p = self.T / (l_ +0.0)\n",
    "            is_full = True\n",
    "            g = mark.index([m for m in mark if m > p][0]) + 1\n",
    "            cluster = 2 ** (g - 1)  # Number of children of the last generation\n",
    "            if (self.T - mark[g-2]*l_) < cluster:\n",
    "                # Explain that adding more generations is better than keeping a few\n",
    "                is_full = False\n",
    "                g -= 1\n",
    "                k = 0\n",
    "            else:\n",
    "                k = l_ - round((self.T - mark[g-2]*l_)/cluster)\n",
    "            self.generate_new_sample(bin1, bin2, g, l_, k, is_full)\n",
    "            # Return data and labels\n",
    "            label_new = np.ones(len(self.new))+ (i-1)\n",
    "            data = np.append(data, self.new, axis=0)\n",
    "            data = pd.DataFrame(data)\n",
    "            label = np.append(label, label_new, axis=0)\n",
    "        return data, label \n",
    "\n",
    "    def mahalanobis_distance(self, x):\n",
    "        x_mu = x - np.mean(x)\n",
    "        cov = np.cov(x.T)\n",
    "        inv_covmat = np.linalg.inv(cov)\n",
    "        left = np.dot(x_mu, inv_covmat)\n",
    "        mahal = np.dot(left, x_mu.T).diagonal()\n",
    "        return mahal\n",
    "\n",
    "\n",
    "    # Generate new samples\n",
    "    def generate_new_sample(self, bin1, bin2, g, l, k, is_full):\n",
    "        # bin1, bin2 are arrays\n",
    "        # g Hereditary remaining algebra\n",
    "        # l bin1 number of items\n",
    "        # k The number of each node to be cropped in the last generation\n",
    "        # is_full whether it overflows, that is, the last generation is counted, whether it exceeds T, or is not full\n",
    "        assert len(bin1) <= len(bin2)\n",
    "        if g >= 2 or (g == 1 and is_full is False):\n",
    "            lv_0 = []  # Offspring\n",
    "            for i in range(l):\n",
    "                # Generate children\n",
    "                lv_0.append(np.mean(np.append(np.atleast_2d(bin1[i]), np.atleast_2d(bin2[i]), axis=0), axis=0))\n",
    "            self.new.extend(lv_0)\n",
    "            self.generate_new_sample(lv_0, bin1, g-1, l, k, is_full)\n",
    "            self.generate_new_sample(lv_0, bin2, g-1, l, k, is_full)\n",
    "        if g == 1 and is_full:\n",
    "            lv_0 = []  # Offspring\n",
    "            for i in range(l):\n",
    "                # Generate children\n",
    "                lv_0.append(np.mean(np.append(np.atleast_2d(bin1[i]), np.atleast_2d(bin2[i]), axis=0), axis=0))\n",
    "            del lv_0[-1: (-k-1): -1]\n",
    "            self.new.extend(lv_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "xtA3GN2Sa6ou"
   },
   "outputs": [],
   "source": [
    "def MAHAKIL_sampling (data, imbalance, seed, num_classes):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  mk = MAHAKIL(pfp=0.5)\n",
    "  X_train_scaled, y_train = mk.fit_sample(X_train_scaled, y_train, num_classes)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MDO_sampling (data, imbalance, seed, num_classes):\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  mk = MAHAKIL(pfp=0.5)\n",
    "  X_train_scaled, y_train = mk.fit_sample(X_train_scaled, y_train, num_classes)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "onLRdNao8J1n"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def a_value(probabilities, zero_label=0, one_label=1):\n",
    "    # Obtain a list of the probabilities for the specified zero label class\n",
    "    expanded_points = []\n",
    "    for instance in probabilities:\n",
    "        if instance[0] == zero_label or instance[0] == one_label:\n",
    "            expanded_points.append((instance[0], instance[1],zero_label))\n",
    "    sorted_ranks = sorted(expanded_points, key=lambda x: x[1])\n",
    "\n",
    "    n0, n1, sum_ranks = 0, 0, 0\n",
    "    # Iterate through ranks and increment counters for overall count and ranks of class 0\n",
    "    for index, point in enumerate(sorted_ranks):\n",
    "        if point[0] == zero_label:\n",
    "            n0 += 1\n",
    "            sum_ranks += index + 1  # Add 1 as ranks are one-based\n",
    "        elif point[0] == one_label:\n",
    "            n1 += 1\n",
    "        else:\n",
    "            pass  # Not interested in this class\n",
    "        if n0 ==0:\n",
    "          n0 = 1\n",
    "        if n1 == 0:\n",
    "          n1 = 1\n",
    "\n",
    "\n",
    "    return (sum_ranks - (n0*(n0+1)/2.0)) / float(n0 * n1)  # Eqn 3\n",
    "\n",
    "def MAUC(data, num_classes):\n",
    "    # Find all pairwise comparisons of labels\n",
    "    class_pairs = [x for x in combinations(range(num_classes), 2)]\n",
    "\n",
    "    # Have to take average of A value with both classes acting as label 0 as this\n",
    "    # gives different outputs for more than 2 classes\n",
    "    sum_avals = 0\n",
    "    for pairing in class_pairs:\n",
    "        sum_avals += (a_value(data, zero_label=pairing[0], one_label=pairing[1]) +\n",
    "                      a_value(data, zero_label=pairing[1], one_label=pairing[0])) / 2.0\n",
    "\n",
    "    return sum_avals * (2 / float(num_classes * (num_classes-1)))  # Eqn 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rRIAtvKez30l"
   },
   "outputs": [],
   "source": [
    "def classifier_results (data, imbalance, sampling_method, model, seed):\n",
    "\n",
    "  num_classes = len(data['class'].value_counts())\n",
    "  \n",
    "  if sampling_method == 'none':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
    "\n",
    "  if sampling_method == 'SMOTE':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = SMOTE_sampling (data, imbalance, seed)\n",
    "  \n",
    "  if sampling_method == 'SWIM':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = SWIM_sampling (data, imbalance, seed, num_classes)\n",
    "  \n",
    "  if sampling_method == 'MAHAKIL':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = MAHAKIL_sampling(data, imbalance, seed, num_classes)\n",
    "  \n",
    "  if sampling_method == 'MDO':\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = MDO_sampling(data, imbalance, seed, num_classes)\n",
    "\n",
    "  if model == 'naive_bayes':\n",
    "    model_func = GaussianNB()\n",
    "\n",
    "  elif model == 'K_neighbours':\n",
    "    model_func = KNeighborsClassifier(n_neighbors=3)\n",
    "  \n",
    "  elif model == 'Random_forest':\n",
    "    model_func = RandomForestClassifier()\n",
    "  \n",
    "  elif model == 'SVM':\n",
    "    model_func = SVC(kernel='rbf', gamma=1, C=1, probability=True, decision_function_shape='ovo')\n",
    "\n",
    "  model_base = model_func\n",
    "  model_base.fit(X_train_scaled, y_train)\n",
    "\n",
    "  y_pred = model_base.predict(X_test_scaled)\n",
    "  y_pred_probs = model_base.predict_proba(X_test_scaled)\n",
    "\n",
    "  probabilities = []\n",
    "  for i in range(len(y_pred)):\n",
    "    element = (y_pred_probs[i])\n",
    "    element = np.insert(element, 0, y_pred[i])\n",
    "    probabilities.append(element)\n",
    "  \n",
    "  score_MAUC = MAUC(probabilities, num_classes)\n",
    "\n",
    "  f1 = f1_score(y_test, y_pred, average=None)\n",
    "  score_f1 = sum(f1[1:])/ (len(f1)-1)\n",
    "  GMS = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "\n",
    "\n",
    "  return [data.name, imbalance, sampling_method, model, score_f1, score_MAUC, GMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier_results(WineW5, 'high', 'SWIM','naive_bayes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wine white - 5 class',\n",
       " 'high',\n",
       " 'SMOTE',\n",
       " 'naive_bayes',\n",
       " 0.2945831808411326,\n",
       " 0.49503128012820996,\n",
       " 0.561063673903039]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wine white - 5 class',\n",
       " 'high',\n",
       " 'SWIM',\n",
       " 'naive_bayes',\n",
       " 0.2966143593844299,\n",
       " 0.4936744657596617,\n",
       " 0.5487389510745855]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wine white - 5 class',\n",
       " 'high',\n",
       " 'MDO',\n",
       " 'naive_bayes',\n",
       " 0.2622469307726436,\n",
       " 0.4943515379624168,\n",
       " 0.5233952863913515]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "B_Mn6FqJjv8k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "Majority class data is singular. Degrading to random oversampling with Gaussian jitter\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n",
      "The majority class has linearly dependent columns. Rerun the sampling subSpaceSampling=True. Return original data.\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "datasets = [WineW3, WineR3, vowel_3, WineW5, WineR5, ecoli, heart, glass]\n",
    "imbalance = ['none','high','extreme']\n",
    "sampling_method = ['none','SMOTE', 'MAHAKIL','SWIM', 'MDO']\n",
    "models = ['naive_bayes', 'Random_forest']\n",
    "for data in datasets:\n",
    "  for i in imbalance: \n",
    "    for s in sampling_method:\n",
    "      for m in models:\n",
    "        for seed in range(3):\n",
    "          try:\n",
    "            results = classifier_results (data, i, s, m, seed) \n",
    "            all_results.append(results)\n",
    "          except:\n",
    "            pass\n",
    "\n",
    "df = pd.DataFrame(all_results, columns=['Data', 'Imbalance_level','Sampling_method', 'Model', 'F1', 'MAUC', 'G_mean'])\n",
    "df.to_csv('multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Imbalance_level</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.561472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.561472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.561472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.417467</td>\n",
       "      <td>0.452179</td>\n",
       "      <td>0.625266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.445628</td>\n",
       "      <td>0.455872</td>\n",
       "      <td>0.637041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>extreme</td>\n",
       "      <td>MDO</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.385348</td>\n",
       "      <td>0.288487</td>\n",
       "      <td>0.589808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>extreme</td>\n",
       "      <td>MDO</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.388892</td>\n",
       "      <td>0.281550</td>\n",
       "      <td>0.642225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>extreme</td>\n",
       "      <td>MDO</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.566061</td>\n",
       "      <td>0.180783</td>\n",
       "      <td>0.715324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>extreme</td>\n",
       "      <td>MDO</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.677357</td>\n",
       "      <td>0.290506</td>\n",
       "      <td>0.796741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>extreme</td>\n",
       "      <td>MDO</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.466573</td>\n",
       "      <td>0.221368</td>\n",
       "      <td>0.670508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Data Imbalance_level Sampling_method          Model  \\\n",
       "0    Wine white - 3 class            none            none    naive_bayes   \n",
       "1    Wine white - 3 class            none            none    naive_bayes   \n",
       "2    Wine white - 3 class            none            none    naive_bayes   \n",
       "3    Wine white - 3 class            none            none  Random_forest   \n",
       "4    Wine white - 3 class            none            none  Random_forest   \n",
       "..                    ...             ...             ...            ...   \n",
       "660               Glass 1         extreme             MDO    naive_bayes   \n",
       "661               Glass 1         extreme             MDO    naive_bayes   \n",
       "662               Glass 1         extreme             MDO  Random_forest   \n",
       "663               Glass 1         extreme             MDO  Random_forest   \n",
       "664               Glass 1         extreme             MDO  Random_forest   \n",
       "\n",
       "           F1      MAUC    G_mean  \n",
       "0    0.184659  0.486920  0.561472  \n",
       "1    0.184659  0.486920  0.561472  \n",
       "2    0.184659  0.486920  0.561472  \n",
       "3    0.417467  0.452179  0.625266  \n",
       "4    0.445628  0.455872  0.637041  \n",
       "..        ...       ...       ...  \n",
       "660  0.385348  0.288487  0.589808  \n",
       "661  0.388892  0.281550  0.642225  \n",
       "662  0.566061  0.180783  0.715324  \n",
       "663  0.677357  0.290506  0.796741  \n",
       "664  0.466573  0.221368  0.670508  \n",
       "\n",
       "[665 rows x 7 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "kq0v0moHdSeu",
    "outputId": "c31c7cad-9a42-4900-dde5-de3da6c70074"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>Imbalance_level</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>extreme</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>extreme</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>high</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>high</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>extreme</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>high</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>high</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Data Sampling_method Imbalance_level          Model  \\\n",
       "0                 Ecoli 1         MAHAKIL         extreme  Random_forest   \n",
       "1                 Ecoli 1         MAHAKIL         extreme    naive_bayes   \n",
       "2                 Ecoli 1         MAHAKIL            high  Random_forest   \n",
       "3                 Ecoli 1         MAHAKIL            high    naive_bayes   \n",
       "4                 Ecoli 1         MAHAKIL            none  Random_forest   \n",
       "..                    ...             ...             ...            ...   \n",
       "223  Wine white - 5 class            none         extreme    naive_bayes   \n",
       "224  Wine white - 5 class            none            high  Random_forest   \n",
       "225  Wine white - 5 class            none            high    naive_bayes   \n",
       "226  Wine white - 5 class            none            none  Random_forest   \n",
       "227  Wine white - 5 class            none            none    naive_bayes   \n",
       "\n",
       "        F1   MAUC  G_mean  \n",
       "0    0.723  0.418   0.871  \n",
       "1    0.432  0.334   0.746  \n",
       "2    0.656  0.409   0.851  \n",
       "3    0.433  0.412   0.767  \n",
       "4    0.806  0.404   0.900  \n",
       "..     ...    ...     ...  \n",
       "223  0.081  0.351   0.440  \n",
       "224  0.226  0.445   0.508  \n",
       "225  0.191  0.478   0.498  \n",
       "226  0.540  0.470   0.689  \n",
       "227  0.309  0.369   0.557  \n",
       "\n",
       "[228 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.groupby(\n",
    "   ['Data','Sampling_method','Imbalance_level', 'Model']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'MAUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "test = test.reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>Imbalance_level</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>high</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>none</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>high</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>high</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>none</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>high</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Data Sampling_method Imbalance_level     F1   MAUC  \\\n",
       "0                 Ecoli 1         MAHAKIL         extreme  0.723  0.418   \n",
       "1                 Ecoli 1         MAHAKIL            high  0.656  0.412   \n",
       "2                 Ecoli 1         MAHAKIL            none  0.806  0.404   \n",
       "3                 Ecoli 1             MDO         extreme  0.748  0.408   \n",
       "4                 Ecoli 1             MDO            high  0.682  0.412   \n",
       "..                    ...             ...             ...    ...    ...   \n",
       "110  Wine white - 5 class            SWIM            high  0.304  0.495   \n",
       "111  Wine white - 5 class            SWIM            none  0.492  0.494   \n",
       "112  Wine white - 5 class            none         extreme  0.081  0.351   \n",
       "113  Wine white - 5 class            none            high  0.226  0.478   \n",
       "114  Wine white - 5 class            none            none  0.540  0.470   \n",
       "\n",
       "     G_mean  \n",
       "0     0.871  \n",
       "1     0.851  \n",
       "2     0.900  \n",
       "3     0.877  \n",
       "4     0.837  \n",
       "..      ...  \n",
       "110   0.624  \n",
       "111   0.724  \n",
       "112   0.440  \n",
       "113   0.508  \n",
       "114   0.689  \n",
       "\n",
       "[115 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = test.groupby(\n",
    "   ['Data','Sampling_method','Imbalance_level']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"max\",  \n",
    "         'MAUC': 'max',\n",
    "         'G_mean': \"max\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "test2 = test2.reset_index()\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "Iy8R7KGDghK3",
    "outputId": "95cdf936-e8c3-4acf-a215-22d7a8055871"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sampling_method</th>\n",
       "      <th>F1</th>\n",
       "      <th>MAUC</th>\n",
       "      <th>G_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecoli 1</td>\n",
       "      <td>none</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Glass 1</td>\n",
       "      <td>none</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart 1</td>\n",
       "      <td>none</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vowel - 3 classes</td>\n",
       "      <td>none</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wine red - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wine white - 3 class</td>\n",
       "      <td>none</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>MAHAKIL</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>MDO</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>SWIM</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Wine white - 5 class</td>\n",
       "      <td>none</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Data Sampling_method     F1   MAUC  G_mean\n",
       "0                Ecoli 1         MAHAKIL  0.656  0.412   0.851\n",
       "1                Ecoli 1             MDO  0.682  0.412   0.837\n",
       "2                Ecoli 1           SMOTE  0.719  0.408   0.854\n",
       "3                Ecoli 1            SWIM  0.736  0.408   0.871\n",
       "4                Ecoli 1            none  0.676  0.411   0.849\n",
       "5                Glass 1         MAHAKIL  0.580  0.266   0.748\n",
       "6                Glass 1             MDO  0.433  0.244   0.650\n",
       "7                Glass 1           SMOTE  0.652  0.287   0.794\n",
       "8                Glass 1            SWIM  0.666  0.309   0.808\n",
       "9                Glass 1            none  0.545  0.265   0.711\n",
       "10               Heart 1         MAHAKIL  0.121  0.311   0.476\n",
       "11               Heart 1             MDO  0.149  0.277   0.475\n",
       "12               Heart 1           SMOTE  0.144  0.326   0.496\n",
       "13               Heart 1            SWIM  0.138  0.328   0.441\n",
       "14               Heart 1            none  0.182  0.405   0.498\n",
       "15     Vowel - 3 classes         MAHAKIL  0.832  0.471   0.888\n",
       "16     Vowel - 3 classes             MDO  0.793  0.471   0.864\n",
       "17     Vowel - 3 classes           SMOTE  0.890  0.479   0.919\n",
       "18     Vowel - 3 classes            SWIM  0.806  0.486   0.961\n",
       "19     Vowel - 3 classes            none  0.742  0.465   0.807\n",
       "20    Wine red - 3 class         MAHAKIL  0.083  0.491   0.593\n",
       "21    Wine red - 3 class             MDO  0.083  0.491   0.593\n",
       "22    Wine red - 3 class           SMOTE  0.220  0.492   0.605\n",
       "23    Wine red - 3 class            SWIM  0.160  0.490   0.652\n",
       "24    Wine red - 3 class            none  0.125  0.452   0.551\n",
       "25  Wine white - 3 class         MAHAKIL  0.393  0.498   0.651\n",
       "26  Wine white - 3 class             MDO  0.396  0.498   0.653\n",
       "27  Wine white - 3 class           SMOTE  0.402  0.497   0.679\n",
       "28  Wine white - 3 class            SWIM  0.309  0.496   0.749\n",
       "29  Wine white - 3 class            none  0.419  0.487   0.627\n",
       "30  Wine white - 5 class         MAHAKIL  0.310  0.493   0.538\n",
       "31  Wine white - 5 class             MDO  0.306  0.494   0.538\n",
       "32  Wine white - 5 class           SMOTE  0.296  0.495   0.582\n",
       "33  Wine white - 5 class            SWIM  0.304  0.495   0.624\n",
       "34  Wine white - 5 class            none  0.226  0.478   0.508"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = test2.copy(deep=True)\n",
    "high = group[(group['Imbalance_level']== 'high')]\n",
    "high = high.groupby(\n",
    "   ['Data', 'Sampling_method']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'MAUC': 'mean',\n",
    "         'G_mean': 'mean'  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "high = high.reset_index()\n",
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww1pC5eJBsW_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/content/drive/MyDrive/Comparison_datasets.json\")\n",
    "df = df.replace({'none': 'None', 'high': 'High', 'extreme':'Extreme', 'absolute':'Absolute'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwyohXdLUWjl"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuXiJezeHrRq"
   },
   "outputs": [],
   "source": [
    "group = df.copy(deep=True)\n",
    "high = group[(group['Imbalance_level']== 'High')]\n",
    "high = high.groupby(\n",
    "   ['Sampling_method', 'Data']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'AUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "high = high.reset_index()\n",
    "high = high.sort_values(by=['Data', 'Sampling_method'])\n",
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbHqgvzHH6Nd"
   },
   "outputs": [],
   "source": [
    "group = df.copy(deep=True)\n",
    "extreme = group[(group['Imbalance_level']== 'High')]\n",
    "extreme = extreme.groupby(\n",
    "   ['Sampling_method', 'Data']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'AUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "extreme = extreme.reset_index()\n",
    "extreme = extreme.sort_values(by=['Data', 'Sampling_method'])\n",
    "extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnoUTZiZIIEY"
   },
   "outputs": [],
   "source": [
    "group = df.copy(deep=True)\n",
    "absolute = group[(group['Imbalance_level']== 'High')]\n",
    "absolute = absolute.groupby(\n",
    "   ['Sampling_method', 'Data']\n",
    ").agg(\n",
    "    {  \n",
    "         'F1': \"mean\",  \n",
    "         'AUC': 'mean',\n",
    "         'G_mean': \"mean\",  \n",
    "    }\n",
    ").round(decimals=3)\n",
    "absolute = absolute.reset_index()\n",
    "absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38g43F__EB53"
   },
   "outputs": [],
   "source": [
    "df[\"Imbalance_level/ Sampling method\"] = df[\"Imbalance_level\"] + \"/\" + df[\"Sampling_method\"]\n",
    "df[\"Imbalance_level/ Sampling method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5rt-KAVArta"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n",
    "fig.suptitle('F1 Model Score by Data Imbalance')\n",
    "high = df[(df['Imbalance_level']== 'High')]\n",
    "extreme = df[(df['Imbalance_level']== 'Extreme')]\n",
    "absolute = df[(df['Imbalance_level']== 'Absolute')]\n",
    "sns.boxplot(ax=axes[0], x=\"Model\", y=\"F1\", data=high, palette=\"mako\")\n",
    "axes[0].set_title(\"High Imbalance\")\n",
    "sns.boxplot(ax=axes[1], x=\"Model\", y=\"F1\", data=extreme, palette=\"mako\")\n",
    "axes[1].set_title(\"Extreme Imbalance\")\n",
    "sns.boxplot(ax=axes[2], x=\"Model\", y=\"F1\", data= absolute, palette=\"mako\")\n",
    "axes[2].set_title(\"Absolute Imbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2vkK8LtFevj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qd-wfXJhBbWw"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x=\"Imbalance_level/ Sampling method\", y=\"F1\", data=df, palette=\"mako\")\n",
    "plt.axvline(x=3.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=7.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=11.5, ymin=0, ymax=40000, color='black')\n",
    "plt.title('F1 score per sampling method - for three imbalance levels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdBAO-7eOBBo"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x=\"Imbalance_level/ Sampling method\", y=\"AUC\", data=df, palette=\"mako\")\n",
    "plt.axvline(x=3.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=7.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=11.5, ymin=0, ymax=40000, color='black')\n",
    "plt.title('AUC score per sampling method - for three imbalance levels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rCm11AJNJh_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x=\"Imbalance_level/ Sampling method\", y=\"G_mean\", data=df, palette=\"mako\")\n",
    "plt.axvline(x=3.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=7.5, ymin=0, ymax=40000, color='black')\n",
    "plt.axvline(x=11.5, ymin=0, ymax=40000, color='black')\n",
    "plt.title('Geometric mean score per sampling method - for three imbalance levels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1U7UHHdGNS90"
   },
   "outputs": [],
   "source": [
    "import multi_imbalance.resampling.mdo as sample_mdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASgYOYxZEz8r"
   },
   "outputs": [],
   "source": [
    " !pip install multi_imbalance"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Emma Diss Re-write - multi.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
