{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmmaDiss.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "62iiPEpGdPsC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from random import randint \n",
        "import random \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, plot_confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB7KgSFTfciI"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQODfSOZdSTj",
        "outputId": "32dda7f4-07ce-4ae1-b5bd-0894b2f72a76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24HmXZKdWcv"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLYzAwiLeED5",
        "outputId": "a3e468be-ca81-4c27-923d-acbdba8e4cbc"
      },
      "source": [
        "import SWIM_maha\n",
        "SWIM_maha.SwimMaha()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SWIM_maha.SwimMaha at 0x7f647f3d0b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WddsjVmgeVb_",
        "outputId": "4487f55b-59b4-4c85-d31b-e73ed7433624"
      },
      "source": [
        "import mahakil_update as MAHAKIL\n",
        "MAHAKIL.MAHAKIL()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mahakil_update.MAHAKIL at 0x7f647f3d0e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-qnMTUjaXJ-"
      },
      "source": [
        "wine_white = pd.read_csv('/content/drive/MyDrive/winequality-white.csv', delimiter=';')\n",
        "wine_red = pd.read_csv('/content/drive/MyDrive/winequality-red.csv', delimiter=';')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSsIvFQ7aag6",
        "outputId": "4f69cdf3-05c5-4260-cb8f-a7229d4558f1"
      },
      "source": [
        "# White Wine Quality Low vs High\n",
        "WineWLvH = deepcopy(wine_white)\n",
        "WineWLvH = WineWLvH[(WineWLvH['quality'] <5)| (WineWLvH['quality'] >6)]\n",
        "WineWLvH.loc[WineWLvH.quality >= 7, \"class\"] = 0\n",
        "WineWLvH.loc[WineWLvH.quality <= 4, \"class\"] = 1\n",
        "WineWLvH['class'] = WineWLvH['class'].astype(\"int\")\n",
        "WineWLvH['class'] = WineWLvH['class'].astype(\"category\")\n",
        "WineWLvH = WineWLvH.drop(columns=['quality'])\n",
        "print(WineWLvH['class'].value_counts())\n",
        "WineWLvH.name = 'D10 - Wine_white_LvH'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1060\n",
            "1     183\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4AugjdXacvF",
        "outputId": "ac72b04f-cfa6-4e6e-8540-72429b369619"
      },
      "source": [
        "# Low Quality Red Wine (3,4)\n",
        "WineRL = deepcopy(wine_red)\n",
        "WineRL[\"class\"] = \"\"\n",
        "WineRL.loc[WineRL.quality >= 5, \"class\"] = 0\n",
        "WineRL.loc[WineRL.quality <= 4, \"class\"] = 1\n",
        "WineRL['class'] = WineRL['class'].astype(\"category\")\n",
        "WineRL = WineRL.drop(columns=['quality'])\n",
        "WineRL.name = 'D11 - Wine_red_low'\n",
        "WineRL['class'].value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1536\n",
              "1      63\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW8hcRTZafsO",
        "outputId": "da55806d-643d-4c0a-df4b-175aa77be18c"
      },
      "source": [
        "# Red Wine Quality Low vs High\n",
        "WineRLvH = deepcopy(wine_red)\n",
        "WineRLvH = WineRLvH[(WineRLvH['quality'] <5)| (WineRLvH['quality'] >6)]\n",
        "WineRLvH.loc[WineRLvH.quality >= 7, \"class\"] = 0\n",
        "WineRLvH.loc[WineRLvH.quality <= 4, \"class\"] = 1\n",
        "WineRLvH['class'] = WineRLvH['class'].astype(\"int\")\n",
        "WineRLvH['class'] = WineRLvH['class'].astype(\"category\")\n",
        "WineRLvH = WineRLvH.drop(columns=['quality'])\n",
        "print(WineRLvH['class'].value_counts())\n",
        "WineRLvH.name ='D12 - Wine_red_LvH'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    217\n",
            "1     63\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgaEXmOJagWJ"
      },
      "source": [
        "vowel = pd.read_csv('/content/drive/MyDrive/vowel_data.data', header=None)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ytm0mtaiS8"
      },
      "source": [
        "vowel = vowel.drop(columns=[10])\n",
        "vowel = vowel.dropna()\n",
        "cols_to_check = [0,9]\n",
        "vowel[cols_to_check] = vowel[cols_to_check].replace({'{':''}, regex=True)\n",
        "vowel[cols_to_check] = vowel[cols_to_check].replace({'}':''}, regex=True)\n",
        "vowel = vowel.reset_index(drop=True)\n",
        "vowel[9] = pd.to_numeric(vowel[9])\n",
        "vowel = vowel.apply(pd.to_numeric)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilmKyRKrall-"
      },
      "source": [
        "speakers = ['Andrew', 'Bill', 'David', 'Mark', 'Jo', 'Kate', 'Penny', 'Rose', 'Mike', 'Nick', 'Rich', 'Tim', 'Sarah', 'Sue', 'Wendy']\n",
        "words = ['hid', 'hId', 'hEd', 'hAd', 'hYd', 'had', 'hOd', 'hod', 'hUd', 'hud', 'hed']\n",
        "segments = [0,1,2,3,4,5]\n",
        "speakers_1 = []\n",
        "words_1 = []\n",
        "segment = []\n",
        "for s in speakers:\n",
        "  for se in segments:\n",
        "    for w in words:\n",
        "      speakers_1.append(s)\n",
        "      segment.append(se)\n",
        "      words_1.append(w)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sivKeb4LampC"
      },
      "source": [
        "vowel['word'] = np.arange(len(vowel))\n",
        "vowel['speaker'] = np.arange(len(vowel))\n",
        "vowel['segment'] = np.arange(len(vowel))\n",
        "for l in range(len(vowel)):\n",
        "  vowel['speaker'] = vowel['speaker'].replace(l, speakers_1[l])\n",
        "  vowel['word'] = vowel['word'].replace(l, words_1[l])\n",
        "  vowel['segment'] = vowel['segment'].replace(l, segment[l])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7psCi70aqdu"
      },
      "source": [
        "vowel['class']= ''\n",
        "# Vowel 0 \n",
        "vowel_0 = deepcopy(vowel)\n",
        "vowel_0.loc[vowel_0.word != 'hid', \"class\"] = 0\n",
        "vowel_0.loc[vowel_0.word == 'hid', \"class\"] = 1\n",
        "vowel_0['class'] = vowel_0['class'].astype(\"int\")\n",
        "vowel_0['class'] = vowel_0['class'].astype(\"category\")\n",
        "vowel_0 = vowel_0.drop(columns=['word','speaker','segment'])\n",
        "vowel_0['class'].value_counts()\n",
        "vowel_0.name = 'D3 - Vowel_0'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHC0ZiXDasv2",
        "outputId": "544641f8-dc0d-4213-81f4-e6928cdcfd61"
      },
      "source": [
        "# Vowel 2\n",
        "vowel_2 = deepcopy(vowel)\n",
        "vowel_2.loc[vowel_2.word != 'hEd', \"class\"] = 0\n",
        "vowel_2.loc[vowel_2.word == 'hEd', \"class\"] = 1\n",
        "vowel_2['class'] = vowel_2['class'].astype(\"int\")\n",
        "vowel_2['class'] = vowel_2['class'].astype(\"category\")\n",
        "vowel_2 = vowel_2.drop(columns=['word','speaker','segment'])\n",
        "print(vowel_2['class'].value_counts())\n",
        "vowel_2.name = 'D4 - Vowel_2'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    900\n",
            "1     90\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsUspqauau3P"
      },
      "source": [
        "# train test/ scaling\n",
        "def data_prep (data, seed):\n",
        "  X= data.drop('class',axis=1).copy()\n",
        "  y = data['class'].copy()\n",
        "  y = y.astype('category')\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed, shuffle=y, stratify=y) # add ssed\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "  X_train_scaled = scaler.transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n",
        "  X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns)\n",
        "\n",
        "  return X_train_scaled, X_test_scaled, y_train, y_test"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvOPEae0aw_a"
      },
      "source": [
        "# random undersamping imbalance levels (high (5%), extreme (1%), absolute (6 samples)\n",
        "def random_under_minority (data, imbalance_level, seed):\n",
        "\n",
        "  random.seed(seed)\n",
        "  \n",
        "  X_train_scaled, X_test_scaled, y_train, y_test = data_prep(data, seed)\n",
        "  y_train = y_train.reset_index(drop=True)\n",
        "  X_train_scaled['class'] = y_train\n",
        "\n",
        "  class_counts = X_train_scaled['class'].value_counts().to_frame()\n",
        "  maj_count = class_counts.iloc[0,0]\n",
        "  min_count = class_counts.iloc[1,0]\n",
        "\n",
        "  majority = X_train_scaled[(X_train_scaled['class'] == 0)]\n",
        "  minority = X_train_scaled[(X_train_scaled['class']== 1)]\n",
        "\n",
        "  if imbalance_level == 'absolute':\n",
        "    downsample = 6\n",
        "  \n",
        "  else:\n",
        "    if imbalance_level == 'high':\n",
        "      imbalance = 0.05\n",
        "      \n",
        "    elif imbalance_level == 'extreme':\n",
        "      imbalance = 0.01\n",
        "\n",
        "    downsample = (maj_count * imbalance).round().astype('int')\n",
        "    \n",
        "    if imbalance_level == 'extreme' and downsample < 8:\n",
        "      downsample = 8\n",
        " \n",
        "  if downsample >= min_count:\n",
        "    minority_sample = minority\n",
        "      \n",
        "  else:\n",
        "    minority_sample = minority.sample(n= downsample)\n",
        "\n",
        "  final = pd.concat([majority, minority_sample])\n",
        "  final = shuffle(final)\n",
        "\n",
        "  X_train_scaled = final.drop('class',axis=1).copy()\n",
        "  y_train = final['class'].copy()\n",
        "  y_train = y_train.astype('category')\n",
        "\n",
        "  X_train_scaled = X_train_scaled.values\n",
        "  X_test_scaled = X_test_scaled.values\n",
        "  y_train = y_train.reset_index(drop=True)\n",
        "  y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "  return X_train_scaled, X_test_scaled, y_train, y_test"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8NQNtO3a1dX"
      },
      "source": [
        "def SMOTE_sampling (data, imbalance, seed):\n",
        "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
        "\n",
        "  SMOTE_sample= SMOTE()\n",
        "  X_train_scaled, y_train = SMOTE_sample.fit_resample(X_train_scaled, y_train)\n",
        "  \n",
        "  return X_train_scaled, X_test_scaled, y_train, y_test"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrN3Akp-ES8l"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTVFilIZa4PX"
      },
      "source": [
        "def SWIM_sampling (data, imbalance, seed):\n",
        "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
        "\n",
        "  numSamples = np.sum(y_train==0)-np.sum(y_train==1)\n",
        "  sw = SWIM_maha.SwimMaha(sd= 2)\n",
        "  X_train_scaled, y_train = sw.mahaSampling(X_train_scaled, y_train, numSamples)\n",
        "  \n",
        "  return X_train_scaled, X_test_scaled, y_train, y_test"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtA3GN2Sa6ou"
      },
      "source": [
        "def MAHAKIL_sampling (data, imbalance, seed):\n",
        "  X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
        "\n",
        "  mk = MAHAKIL.MAHAKIL(pfp=0.5)\n",
        "  X_train_scaled, y_train = mk.fit_sample(X_train_scaled, y_train)\n",
        "\n",
        "  maj_count = np.count_nonzero(y_train ==0)\n",
        "\n",
        "  df = pd.DataFrame(X_train_scaled)\n",
        "  df['class'] = y_train\n",
        "  df['class'] = df['class'].astype(int)\n",
        "\n",
        "  majority = df[(df['class'] == 0)]\n",
        "  minority = df[(df['class']== 1)]\n",
        "\n",
        "  minority = minority[0:maj_count]\n",
        "\n",
        "  final = pd.concat([majority, minority])\n",
        "  final = shuffle(final)\n",
        "\n",
        "  X_train_scaled = final.drop('class',axis=1).copy()\n",
        "  y_train = final['class'].copy()\n",
        "  y_train = y_train.astype('category')\n",
        "\n",
        "  X_train_scaled = X_train_scaled.values\n",
        "  y_train = y_train.reset_index(drop=True)\n",
        "\n",
        "  return X_train_scaled, X_test_scaled, y_train, y_test"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRIAtvKez30l"
      },
      "source": [
        "def classifier_results (data, imbalance, sampling_method, model, seed):\n",
        "  \n",
        "  if sampling_method == 'none':\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test = random_under_minority(data, imbalance, seed)\n",
        "\n",
        "  if sampling_method == 'SMOTE':\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test = SMOTE_sampling (data, imbalance, seed)\n",
        "  \n",
        "  if sampling_method == 'SWIM':\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test = SWIM_sampling (data, imbalance, seed)\n",
        "  \n",
        "  if sampling_method == 'MAHAKIL':\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test = MAHAKIL_sampling(data, imbalance, seed)\n",
        "\n",
        "  if model == 'naive_bayes':\n",
        "    model_func = GaussianNB()\n",
        "\n",
        "  elif model == 'K_neighbours':\n",
        "    model_func = KNeighborsClassifier(n_neighbors=3)\n",
        "  \n",
        "  elif model == 'Random_forest':\n",
        "    model_func = RandomForestClassifier()\n",
        "\n",
        "  model_base = model_func\n",
        "  model_base.fit(X_train_scaled, y_train)\n",
        "\n",
        "  y_pred = model_base.predict(X_test_scaled)\n",
        "\n",
        "  score_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "  AUC = roc_auc_score(y_test, y_pred)\n",
        "  GMS = geometric_mean_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "  return [data.name, sampling_method, model, imbalance, score_f1, AUC, GMS]"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLyRb3t69XkK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "30ba16a0-4a6a-47f9-acfc-d31d167a9573"
      },
      "source": [
        "name, sampling_method, model, imbalance, score_f1, AUC, GMS = classifier_results(vowel_0, 'absolute', 'MAHAKIL', 'naive_bayes', 1 )\n",
        "name, sampling_method, model, imbalance, score_f1, AUC, GMS = classifier_results(vowel_0, 'absolute', 'MAHAKIL', 'K_neighbours', 1 )\n",
        "name, sampling_method, model, imbalance, score_f1, AUC, GMS = classifier_results(vowel_0, 'absolute', 'MAHAKIL', 'Random_forest', 1 )"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-e7ad091bce3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimbalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'absolute'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAHAKIL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'naive_bayes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimbalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'absolute'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAHAKIL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'K_neighbours'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimbalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'absolute'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAHAKIL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Random_forest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-196-818d31bbee19>\u001b[0m in \u001b[0;36mclassifier_results\u001b[0;34m(data, imbalance, sampling_method, model, seed)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msampling_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MAHAKIL'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAHAKIL_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimbalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'naive_bayes'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-195-e08097927ee4>\u001b[0m in \u001b[0;36mMAHAKIL_sampling\u001b[0;34m(data, imbalance, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAHAKIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAHAKIL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmaj_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/mahakil_update.py\u001b[0m in \u001b[0;36mfit_sample\u001b[0;34m(self, data, label)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Calculate the Mahalanobis distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmahalanobis_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/mahakil_update.py\u001b[0m in \u001b[0;36mmahalanobis_distance\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mx_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0md_squre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0md_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_squre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "n6zh7vlQfgjd",
        "outputId": "02179e79-5d5f-45a8-c5e5-2c23dee92830"
      },
      "source": [
        "all_results = []\n",
        "datasets = [vowel_0, vowel_2, WineWLvH, WineRL, WineRLvH]\n",
        "imbalance = ['high', 'extreme', 'absolute']\n",
        "sampling_method = ['none', 'SMOTE','SWIM', 'MAHAKIL']\n",
        "models = ['naive_bayes', 'K_neighbours', 'Random_forest']\n",
        "for data in datasets:\n",
        "  for i in imbalance: \n",
        "    for s in sampling_method:\n",
        "      for m in models:\n",
        "        for seed in range(30):\n",
        "          try:\n",
        "            results = classifier_results (data, i, s, m, seed) \n",
        "            all_results.append(results) \n",
        "          except:\n",
        "            pass\n",
        "\n",
        "df = pd.DataFrame(all_results, columns=['Data', 'Sampling_method','Model', 'Imbalance_level', 'F1', 'AUC', 'G_mean'])   \n",
        "df_save = df.to_json(\"/content/drive/MyDrive/Comparison_datasets.json\")\n",
        "df      "
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Sampling_method</th>\n",
              "      <th>Model</th>\n",
              "      <th>Imbalance_level</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "      <th>G_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>none</td>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>high</td>\n",
              "      <td>0.898096</td>\n",
              "      <td>0.921449</td>\n",
              "      <td>0.919987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>none</td>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>high</td>\n",
              "      <td>0.890022</td>\n",
              "      <td>0.882415</td>\n",
              "      <td>0.876753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>none</td>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>high</td>\n",
              "      <td>0.854533</td>\n",
              "      <td>0.910338</td>\n",
              "      <td>0.909425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>none</td>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>high</td>\n",
              "      <td>0.806653</td>\n",
              "      <td>0.842899</td>\n",
              "      <td>0.836487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>none</td>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>high</td>\n",
              "      <td>0.792190</td>\n",
              "      <td>0.838454</td>\n",
              "      <td>0.832550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5307</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>Random_forest</td>\n",
              "      <td>absolute</td>\n",
              "      <td>0.676425</td>\n",
              "      <td>0.646991</td>\n",
              "      <td>0.553817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5308</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>Random_forest</td>\n",
              "      <td>absolute</td>\n",
              "      <td>0.691877</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.559017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5309</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>Random_forest</td>\n",
              "      <td>absolute</td>\n",
              "      <td>0.553734</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.353553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5310</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>Random_forest</td>\n",
              "      <td>absolute</td>\n",
              "      <td>0.543280</td>\n",
              "      <td>0.553241</td>\n",
              "      <td>0.350264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5311</th>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>Random_forest</td>\n",
              "      <td>absolute</td>\n",
              "      <td>0.676425</td>\n",
              "      <td>0.646991</td>\n",
              "      <td>0.553817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5312 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Data Sampling_method          Model  ...        F1       AUC    G_mean\n",
              "0     D3 - Vowel_0            none    naive_bayes  ...  0.898096  0.921449  0.919987\n",
              "1     D3 - Vowel_0            none    naive_bayes  ...  0.890022  0.882415  0.876753\n",
              "2     D3 - Vowel_0            none    naive_bayes  ...  0.854533  0.910338  0.909425\n",
              "3     D3 - Vowel_0            none    naive_bayes  ...  0.806653  0.842899  0.836487\n",
              "4     D3 - Vowel_0            none    naive_bayes  ...  0.792190  0.838454  0.832550\n",
              "...            ...             ...            ...  ...       ...       ...       ...\n",
              "5307  D3 - Vowel_0         MAHAKIL  Random_forest  ...  0.676425  0.646991  0.553817\n",
              "5308  D3 - Vowel_0         MAHAKIL  Random_forest  ...  0.691877  0.656250  0.559017\n",
              "5309  D3 - Vowel_0         MAHAKIL  Random_forest  ...  0.553734  0.562500  0.353553\n",
              "5310  D3 - Vowel_0         MAHAKIL  Random_forest  ...  0.543280  0.553241  0.350264\n",
              "5311  D3 - Vowel_0         MAHAKIL  Random_forest  ...  0.676425  0.646991  0.553817\n",
              "\n",
              "[5312 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Iy8R7KGDghK3",
        "outputId": "ecf82cb2-ef31-4ad7-84d6-0dbbd4c99a5c"
      },
      "source": [
        "group = df.copy(deep=True)\n",
        "high = group[(group['Imbalance_level']== 'high')]\n",
        "high = high.groupby(\n",
        "   ['Sampling_method', 'Data']\n",
        ").agg(\n",
        "    {  \n",
        "         'F1': \"mean\",  \n",
        "         'AUC': 'mean',\n",
        "         'G_mean': \"mean\",  \n",
        "    }\n",
        ").round(decimals=3)\n",
        "high = high.reset_index()\n",
        "high"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sampling_method</th>\n",
              "      <th>Data</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "      <th>G_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>D10 - Wine_white_LvH</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0.696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAHAKIL</td>\n",
              "      <td>D4 - Vowel_2</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SMOTE</td>\n",
              "      <td>D10 - Wine_white_LvH</td>\n",
              "      <td>0.790</td>\n",
              "      <td>0.790</td>\n",
              "      <td>0.772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SMOTE</td>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SMOTE</td>\n",
              "      <td>D4 - Vowel_2</td>\n",
              "      <td>0.887</td>\n",
              "      <td>0.912</td>\n",
              "      <td>0.908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SWIM</td>\n",
              "      <td>D10 - Wine_white_LvH</td>\n",
              "      <td>0.783</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SWIM</td>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SWIM</td>\n",
              "      <td>D4 - Vowel_2</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>none</td>\n",
              "      <td>D10 - Wine_white_LvH</td>\n",
              "      <td>0.727</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>none</td>\n",
              "      <td>D3 - Vowel_0</td>\n",
              "      <td>0.701</td>\n",
              "      <td>0.695</td>\n",
              "      <td>0.541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>none</td>\n",
              "      <td>D4 - Vowel_2</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.769</td>\n",
              "      <td>0.717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sampling_method                  Data     F1    AUC  G_mean\n",
              "0          MAHAKIL  D10 - Wine_white_LvH  0.792  0.780   0.757\n",
              "1          MAHAKIL          D3 - Vowel_0  0.725  0.754   0.696\n",
              "2          MAHAKIL          D4 - Vowel_2  0.900  0.909   0.903\n",
              "3            SMOTE  D10 - Wine_white_LvH  0.790  0.790   0.772\n",
              "4            SMOTE          D3 - Vowel_0  0.732  0.767   0.728\n",
              "5            SMOTE          D4 - Vowel_2  0.887  0.912   0.908\n",
              "6             SWIM  D10 - Wine_white_LvH  0.783  0.804   0.794\n",
              "7             SWIM          D3 - Vowel_0  0.735  0.788   0.754\n",
              "8             SWIM          D4 - Vowel_2  0.804  0.925   0.921\n",
              "9             none  D10 - Wine_white_LvH  0.727  0.680   0.598\n",
              "10            none          D3 - Vowel_0  0.701  0.695   0.541\n",
              "11            none          D4 - Vowel_2  0.815  0.769   0.717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    }
  ]
}